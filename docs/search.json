[
  {
    "objectID": "tidytuesday_exercise.html",
    "href": "tidytuesday_exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "library(tidytuesdayR)\nlibrary(tidyverse) \n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.1     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(lubridate) #change data type to data\n\nLoading required package: timechange\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(skimr) #skim dataframes\nlibrary(plotly) #interactive plots \n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(ggstatsplot) #stats plots \n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\nlibrary(gt) #create tables \nlibrary(scales) #build unique color pallets\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(knitr) #format table output\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "visualization_exercise.html",
    "href": "visualization_exercise.html",
    "title": "Visualization Exercise",
    "section": "",
    "text": "This data set contains the deaths involving COVID-19, pneumonia, and influenza reported to NCHS by sex, age group, and jurisdiction. This data was obtained from the Centers for Disease Control and Prevention (CDC)’s National Center for Health Statistics (NCHS).\nI decided to recreate some of my figures from last week as interactive graphs.\n\n\n\n\nhere() starts at /Users/deannalanier/Desktop/All_Classes_UGA/2023Spr_Classes/MADA/deannalanier-MADA-portfolio\n\n\nLoading required package: ggplot2\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n✔ purrr   1.0.1      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks plotly::filter(), stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nLoading required package: timechange\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\n\n\n\n\ndata_location=here(\"dataanalysis-exercise\",\"output\",\"clean_data.rds\")\nprocessedData = readRDS(data_location)\n\n\n\n\n\ndata_plot = processedData %>% filter(Group == \"By Year\")\n\n\n#Create list for each of the variable that we want to separate as differnt buttons \n\nCOVID_19 = list(\n  x=processedData$Year, \n  y=processedData$COVID_19_Deaths,\n  xref='x', yref='y'\n)\n\nPneumonia = list(\n  x=processedData$Year, \n  y=processedData$Pneumonia_Deaths,\n  xref='x', yref='y'\n)\n\nInfluenza = list(\n  x=processedData$Year, \n  y=processedData$Influenza_Deaths,\n  xref='x', yref='y'\n)\n\n\nupdatemenus = list(\n  list(\n    active = 0,\n    type= 'buttons',\n    direction = \"right\",\n    xanchor = 'right',\n    yanchor = \"bottom\",\n    pad = list('r'= 0, 't'= 0, 'b' = 0),\n    x = 0.5,\n    y = 1.15,\n    buttons = list(\n      list(\n        label = \"COVID-19\",\n        method = \"update\",\n        args = list(list(visible = c(TRUE, FALSE, FALSE)),\n                    list(title = \"Covid-19 Related Deaths\",\n                         annotations = list(c(), c(), COVID_19)))),\n      list(\n        label = \"Pneumonia\",\n        method = \"update\",\n        args = list(list(visible = c(FALSE, TRUE, FALSE)),\n                    list(title = \"Pneumonia Related Deaths \",\n                         annotations = list( c(), Pneumonia, c())))),\n      list(\n        label = \"Influenza\",\n        method = \"update\",\n        args = list(list(visible = c(FALSE, FALSE, TRUE)),\n                    list(title = \"Influenza Related Deaths\",\n                         annotations = list(Influenza, c(), c())))),\n      list(\n        label = \"All\",\n        method = \"update\",\n        args = list(list(visible = c(TRUE, TRUE, TRUE)),\n                    list(title = \"All Respiratory Virus Related Deaths\",\n                         annotations = list(c(), c(), c())))))\n  )\n)\n\n\nbar_fig = plot_ly(processedData, x = ~Year, y = ~COVID_19_Deaths, type = 'bar', name = 'Covid-19 Deaths')%>% \n  add_trace(y = ~Pneumonia_Deaths, name = 'Pneumonia Deaths')%>% \n  add_trace(y = ~Influenza_Deaths, name = 'Flu Deaths')%>% \n  layout(title = list(text='All Respiratory Virus Related Deaths 2020-2021', y = 0.95, x = 0.5, xanchor = 'left', yanchor =  'bottom'),yaxis = list(title = 'Count'), barmode = 'group',xaxis = list(title = \"Year\"),updatemenus=updatemenus)\n\nbar_fig\n\n\n\n\n\n\n\n\n\nMonth_data_location=here(\"dataanalysis-exercise\",\"data\",\"Provisional_COVID-19_Deaths_by_Sex_and_Age.csv\")\nMonthData = read_csv(Month_data_location)\n\nRows: 115668 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Data As Of, Start Date, End Date, Group, State, Sex, Age Group, Foo...\ndbl (8): Year, Month, COVID-19 Deaths, Total Deaths, Pneumonia Deaths, Pneum...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n#remove special characters\nnames(MonthData) = gsub(\" \", \"_\",\n           gsub(\"-\", \"_\",\n           gsub(\",\", \"\", names(MonthData))))\n\nMonthData = MonthData %>% \n  mutate_at(\n    vars('Data_As_Of', 'Start_Date','End_Date'), \n    as_date,\n    format = \"%m-%d-%y\"\n    )%>% mutate(Year = as.character(Year)) %>% \n  filter(State == \"United States\",Age_Group==\"All Ages\", Sex == \"All Sexes\", Group==\"By Month\", Year == 2020 | Year == 2021 | Year == 2022)%>%\n  select(Start_Date, End_Date, COVID_19_Deaths,Pneumonia_Deaths,Influenza_Deaths, Sex, Year, Month)\n\n###Plot\n\nline_fig = plot_ly(MonthData, type = 'scatter', mode = 'lines', colors = \"Set1\")%>%\n  add_trace(x = ~Start_Date, y = ~COVID_19_Deaths, name = 'Covid-19 Deaths' )%>%\n  add_trace(x = ~Start_Date,y = ~Pneumonia_Deaths, name = 'Pneumonia Deaths')%>%\n  add_trace(x = ~Start_Date,y = ~Influenza_Deaths, name = 'Flu Deaths')%>%\n  layout(paper_bgcolor='#D4D4D4',plot_bgcolor='#D4D4D4',showlegend = T, title='Respiratory virus related deaths 2020-2022',\n         xaxis = list(rangeslider = list(visible = T),\n                      rangeselector=list(\n                        buttons=list(\n                          list(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n                          list(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n                          list(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n                          list(step=\"all\")\n                        ))))\nline_fig = line_fig %>%\n  layout(\n         xaxis = list(zerolinecolor = '#D4D4D4',\n                      zerolinewidth = 2,\n                      gridcolor = '#D4D4D4',color ='000000', title = 'Date'),\n         yaxis = list(zerolinecolor = '#D4D4D4',\n                      zerolinewidth = 2,\n                      gridcolor = '#D4D4D4', color ='000000',title = '# of Deaths'),\n         plot_bgcolor='#fff', width = 800)\n\nWarning: Specifying width/height in layout() is now deprecated.\nPlease specify in ggplotly() or plot_ly()\n\nline_fig\n\n\n\n\n\n##Comments Using Plotly in R was fairly straight forward and I didnt not have any difficulty making these plots interactive. My next goal is to figure out how to use the animation features."
  },
  {
    "objectID": "coding_exercise.html",
    "href": "coding_exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "#install and load required packages\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n#install and load required packages\nlibrary(dslabs)\n#find gapminder data to be used for exercise\n#help(gapminder)\n\n\nstr(gapminder) #get an overview of the data structure\n\n'data.frame':   10545 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  115.4 148.2 208 NA 59.9 ...\n $ life_expectancy : num  62.9 47.5 36 63 65.4 ...\n $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...\n $ population      : num  1636054 11124892 5270844 54681 20619075 ...\n $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 4 1 1 2 2 3 2 5 4 3 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 19 11 10 2 15 21 2 1 22 21 ...\n\n\n\nsummary(gapminder) #get a summary of the data\n\n                country           year      infant_mortality life_expectancy\n Albania            :   57   Min.   :1960   Min.   :  1.50   Min.   :13.20  \n Algeria            :   57   1st Qu.:1974   1st Qu.: 16.00   1st Qu.:57.50  \n Angola             :   57   Median :1988   Median : 41.50   Median :67.54  \n Antigua and Barbuda:   57   Mean   :1988   Mean   : 55.31   Mean   :64.81  \n Argentina          :   57   3rd Qu.:2002   3rd Qu.: 85.10   3rd Qu.:73.00  \n Armenia            :   57   Max.   :2016   Max.   :276.90   Max.   :83.90  \n (Other)            :10203                  NA's   :1453                    \n   fertility       population             gdp               continent   \n Min.   :0.840   Min.   :3.124e+04   Min.   :4.040e+07   Africa  :2907  \n 1st Qu.:2.200   1st Qu.:1.333e+06   1st Qu.:1.846e+09   Americas:2052  \n Median :3.750   Median :5.009e+06   Median :7.794e+09   Asia    :2679  \n Mean   :4.084   Mean   :2.701e+07   Mean   :1.480e+11   Europe  :2223  \n 3rd Qu.:6.000   3rd Qu.:1.523e+07   3rd Qu.:5.540e+10   Oceania : 684  \n Max.   :9.220   Max.   :1.376e+09   Max.   :1.174e+13                  \n NA's   :187     NA's   :185         NA's   :2972                       \n             region    \n Western Asia   :1026  \n Eastern Africa : 912  \n Western Africa : 912  \n Caribbean      : 741  \n South America  : 684  \n Southern Europe: 684  \n (Other)        :5586  \n\n\n\nclass(gapminder) #determine the type of object gapminer is \n\n[1] \"data.frame\""
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deanna Lanier’s website and data analysis portfolio",
    "section": "",
    "text": "Hi There!\n\nWelcome to my website and data analysis portfolio\nHi everyone, I am Deanna Lanier. This website will be used for the Spring 2023 Modern Applied Data Analysis course.\n\nRead more about me on my About Me page above.\nLooking forward to a great semester!"
  },
  {
    "objectID": "coding_exercise.html#process-data-and-plotting",
    "href": "coding_exercise.html#process-data-and-plotting",
    "title": "R Coding Exercise",
    "section": "Process Data and Plotting",
    "text": "Process Data and Plotting\n\n#save all data to \"data\"\ndata = gapminder\n\n# subset based on Continent == Africa\nafricaData = data[ which(data$continent==\"Africa\"), ]\n\nstr(africaData) #get an overview of the data structure\n\n'data.frame':   2907 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n $ fertility       : num  7.65 7.32 6.28 6.62 6.29 6.95 5.65 6.89 5.84 6.25 ...\n $ population      : num  11124892 5270844 2431620 524029 4829291 ...\n $ gdp             : num  1.38e+10 NA 6.22e+08 1.24e+08 5.97e+08 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\n\n\nsummary(gapminder) #get a summary of the data\n\n                country           year      infant_mortality life_expectancy\n Albania            :   57   Min.   :1960   Min.   :  1.50   Min.   :13.20  \n Algeria            :   57   1st Qu.:1974   1st Qu.: 16.00   1st Qu.:57.50  \n Angola             :   57   Median :1988   Median : 41.50   Median :67.54  \n Antigua and Barbuda:   57   Mean   :1988   Mean   : 55.31   Mean   :64.81  \n Argentina          :   57   3rd Qu.:2002   3rd Qu.: 85.10   3rd Qu.:73.00  \n Armenia            :   57   Max.   :2016   Max.   :276.90   Max.   :83.90  \n (Other)            :10203                  NA's   :1453                    \n   fertility       population             gdp               continent   \n Min.   :0.840   Min.   :3.124e+04   Min.   :4.040e+07   Africa  :2907  \n 1st Qu.:2.200   1st Qu.:1.333e+06   1st Qu.:1.846e+09   Americas:2052  \n Median :3.750   Median :5.009e+06   Median :7.794e+09   Asia    :2679  \n Mean   :4.084   Mean   :2.701e+07   Mean   :1.480e+11   Europe  :2223  \n 3rd Qu.:6.000   3rd Qu.:1.523e+07   3rd Qu.:5.540e+10   Oceania : 684  \n Max.   :9.220   Max.   :1.376e+09   Max.   :1.174e+13                  \n NA's   :187     NA's   :185         NA's   :2972                       \n             region    \n Western Asia   :1026  \n Eastern Africa : 912  \n Western Africa : 912  \n Caribbean      : 741  \n South America  : 684  \n Southern Europe: 684  \n (Other)        :5586"
  },
  {
    "objectID": "coding_exercise.html#more-processing",
    "href": "coding_exercise.html#more-processing",
    "title": "R Coding Exercise",
    "section": "More Processing",
    "text": "More Processing\n\n# determine the years with missing values for NA\ninfantNA  = (africaData[is.na(africaData$infant_mortality), ]  )\ntable(infantNA$year)\n\n\n1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 \n  10   17   16   16   15   14   13   11   11    7    5    6    6    6    5    5 \n1976 1977 1978 1979 1980 1981 2016 \n   3    3    2    2    1    1   51 \n\n\n\n# subset year 2000\n\ny_2000 = africaData[ which(africaData$year==\"2000\"), ]\nsummary(y_2000)\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0  \n\n\n\n# Plot life expectancy as a function of infant mortality \n\nggplot(infantM_LifeE, aes(x=infant_mortality, y=life_expectancy)) + geom_point()\n\nWarning: Removed 226 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n# Plot life expectancy as a function of infant mortality \n\nggplot(y_2000, aes(x=population, y=life_expectancy)) + geom_point() +scale_x_continuous(trans='log10')\n\n\n\n\n\n# use lm function and fit life expectancy as the outcome and infant mortality as the predictor. Then use the pipulation size as the predictor (only from 2000) save the result from the two fits into two objects (fit1 and fit2) and apply summary to both \n\n#outcome second predictor first \n\nfit1 = lm(life_expectancy~infant_mortality, data=y_2000)\nfit1_table = broom::tidy(fit1)\nprint(fit1_table)\n\n# A tibble: 2 × 5\n  term             estimate std.error statistic  p.value\n  <chr>               <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)        71.3      2.43       29.4  8.91e-33\n2 infant_mortality   -0.189    0.0287     -6.59 2.83e- 8\n\n\n\nfit2 = lm(life_expectancy~population, data=y_2000)\nfit2_table = broom::tidy(fit2)\nprint(fit2_table)\n\n# A tibble: 2 × 5\n  term             estimate    std.error statistic  p.value\n  <chr>               <dbl>        <dbl>     <dbl>    <dbl>\n1 (Intercept) 55.9          1.47            38.1   4.51e-38\n2 population   0.0000000276 0.0000000546     0.505 6.16e- 1"
  },
  {
    "objectID": "coding_exercise.html#more-processing-and-plotting",
    "href": "coding_exercise.html#more-processing-and-plotting",
    "title": "R Coding Exercise",
    "section": "More Processing and Plotting",
    "text": "More Processing and Plotting\n\n# determine the years with missing values for NA\ninfantNA  = (africaData[is.na(africaData$infant_mortality), ]  )\ntable(infantNA$year)\n\n\n1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 \n  10   17   16   16   15   14   13   11   11    7    5    6    6    6    5    5 \n1976 1977 1978 1979 1980 1981 2016 \n   3    3    2    2    1    1   51"
  },
  {
    "objectID": "coding_exercise.html#simple-fit",
    "href": "coding_exercise.html#simple-fit",
    "title": "R Coding Exercise",
    "section": "Simple Fit",
    "text": "Simple Fit\nlinear model to fit outcome = life expectancy and predictor = infant mortality\n\nfit1 = lm(life_expectancy~infant_mortality, data=y_2000)\nfit1_table = broom::tidy(fit1)\nprint(fit1_table)\n\n# A tibble: 2 × 5\n  term             estimate std.error statistic  p.value\n  <chr>               <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)        71.3      2.43       29.4  8.91e-33\n2 infant_mortality   -0.189    0.0287     -6.59 2.83e- 8"
  },
  {
    "objectID": "coding_exercise.html#section",
    "href": "coding_exercise.html#section",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Infant Mortality and Life Expectancy\n\n#Subset Africa infant mortality and life expectancy\ninfantM_LifeE = africaData[c(\"infant_mortality\", \"life_expectancy\")]\n\nstr(infantM_LifeE) #get an overview of the data structure\n\n'data.frame':   2907 obs. of  2 variables:\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\n\n\nsummary(infantM_LifeE)#get a summary of the data\n\n infant_mortality life_expectancy\n Min.   : 11.40   Min.   :13.20  \n 1st Qu.: 62.20   1st Qu.:48.23  \n Median : 93.40   Median :53.98  \n Mean   : 95.12   Mean   :54.38  \n 3rd Qu.:124.70   3rd Qu.:60.10  \n Max.   :237.40   Max.   :77.60  \n NA's   :226"
  },
  {
    "objectID": "coding_exercise.html#section-1",
    "href": "coding_exercise.html#section-1",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Infant Mortality and Life Expectancy\n\n#Subset Africa infant mortality and life expectancy\ninfantM_LifeE = africaData[c(\"infant_mortality\", \"life_expectancy\")]\n\nstr(infantM_LifeE) #get an overview of the data structure\n\n'data.frame':   2907 obs. of  2 variables:\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\n\n#####this section is added by Weifan\n\n### using select function to extract a data frame only include infant mortality and life expectancy\ninfantM_LifeE2=select(africaData, infant_mortality,life_expectancy)\n###get an overview of the data structure\nstr(infantM_LifeE2)\n\n'data.frame':   2907 obs. of  2 variables:\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\n###get a summary of the data\nsummary(infantM_LifeE2)\n\n infant_mortality life_expectancy\n Min.   : 11.40   Min.   :13.20  \n 1st Qu.: 62.20   1st Qu.:48.23  \n Median : 93.40   Median :53.98  \n Mean   : 95.12   Mean   :54.38  \n 3rd Qu.:124.70   3rd Qu.:60.10  \n Max.   :237.40   Max.   :77.60  \n NA's   :226                     \n\n\n\nsummary(infantM_LifeE)#get a summary of the data\n\n infant_mortality life_expectancy\n Min.   : 11.40   Min.   :13.20  \n 1st Qu.: 62.20   1st Qu.:48.23  \n Median : 93.40   Median :53.98  \n Mean   : 95.12   Mean   :54.38  \n 3rd Qu.:124.70   3rd Qu.:60.10  \n Max.   :237.40   Max.   :77.60  \n NA's   :226"
  },
  {
    "objectID": "coding_exercise.html#section-2",
    "href": "coding_exercise.html#section-2",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Plot life expectancy as a function of infant mortality \n\n# Plot life expectancy as a function of infant mortality \nggplot(infantM_LifeE, aes(x=infant_mortality, y=life_expectancy)) + geom_point()+xlab(\"Infant Mortality\")+ ylab(\"Life Expectancy (Years)\")+\n  theme_bw()\n\nWarning: Removed 226 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "coding_exercise.html#section-3",
    "href": "coding_exercise.html#section-3",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Population and Life Expectancy\n\n#Subset Africa population and life expectancy\npop_LifeE = africaData[c(\"population\", \"life_expectancy\")]\nstr(pop_LifeE) #get an overview of the data structure\n\n'data.frame':   2907 obs. of  2 variables:\n $ population     : num  11124892 5270844 2431620 524029 4829291 ...\n $ life_expectancy: num  47.5 36 38.3 50.3 35.2 ...\n\n\n\nsummary(pop_LifeE) #get a summary of the data\n\n   population        life_expectancy\n Min.   :    41538   Min.   :13.20  \n 1st Qu.:  1605232   1st Qu.:48.23  \n Median :  5570982   Median :53.98  \n Mean   : 12235961   Mean   :54.38  \n 3rd Qu.: 13888152   3rd Qu.:60.10  \n Max.   :182201962   Max.   :77.60  \n NA's   :51"
  },
  {
    "objectID": "coding_exercise.html#section-4",
    "href": "coding_exercise.html#section-4",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Plot life expectancy as a function of population\n\n# Plot life expectancy as a function of population\nggplot(pop_LifeE, aes(x=log(population), y=life_expectancy)) + geom_point() +xlab(\"Population (log)\")+ ylab(\"Life Expectancy (Years)\")+\n  theme_bw()\n\nWarning: Removed 51 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "coding_exercise.html#section-5",
    "href": "coding_exercise.html#section-5",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Year 2000\n\n# subset year 2000\ny_2000 = africaData[ which(africaData$year==\"2000\"), ]\nsummary(y_2000) #get a summary of the data\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0"
  },
  {
    "objectID": "coding_exercise.html#section-6",
    "href": "coding_exercise.html#section-6",
    "title": "R Coding Exercise",
    "section": "",
    "text": "plot life expectancy as a function of infant mortality\n\n# Plot life expectancy as a function of infant mortality \nggplot(y_2000, aes(x=infant_mortality, y=life_expectancy)) + geom_point() +xlab(\"Infant Mortality\")+ ylab(\"Life Expectancy (Years)\")+\n  theme_bw()"
  },
  {
    "objectID": "coding_exercise.html#section-7",
    "href": "coding_exercise.html#section-7",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Plot life expectancy as a function of infant mortality \n\n# Plot life expectancy as a function of infant mortality \n\nggplot(y_2000, aes(x=log(population), y=life_expectancy)) + geom_point() +xlab(\"Population (log)\")+ ylab(\"Life Expectancy (Years)\")+\n  theme_bw()\n\n\n\n\n#####This section added by Weifan\n\n###find out if there is any missing value of fertility and gdp in year 2000\nsummary(y_2000)\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0  \n\n###since there is no missing value in year 2000, we still choose this year to plot life expectancy as a function of fertility\ny_2000%>%\n  ggplot(aes(x=fertility,y=life_expectancy,color=region))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=FALSE,color=\"green\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n  labs(x=\"fertility\",y=\"life_expectancy\", title=\"relationship between life expectancy and fertility\")+\n  theme_minimal()\n\nNULL\n\n###plot life expectancy as a function of gdp\ny_2000%>%\n  ggplot(aes(x=gdp,y=life_expectancy,color=region))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=FALSE,color=\"red\")+\n  labs(x=\"gdp\",y=\"life_expectancy\", title=\"relationship between life expectancy and gdp in five different regions\")+\n  scale_x_log10(labels=scales::dollar_format())\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "coding_exercise.html#section-8",
    "href": "coding_exercise.html#section-8",
    "title": "R Coding Exercise",
    "section": "",
    "text": "linear model to fit outcome = life expectancy and predictor = population\n\nfit2 = lm(life_expectancy~population, data=y_2000)\nfit2_table = broom::tidy(fit2)\nprint(fit2_table)\n\n# A tibble: 2 × 5\n  term             estimate    std.error statistic  p.value\n  <chr>               <dbl>        <dbl>     <dbl>    <dbl>\n1 (Intercept) 55.9          1.47            38.1   4.51e-38\n2 population   0.0000000276 0.0000000546     0.505 6.16e- 1\n\n\n\n\nthis section is added by Weifan\n\n###linear model to predict life expectancy using fertility\nlm1=lm(life_expectancy~fertility, data=y_2000)\ntable1=broom::tidy(lm1)%>%\n  knitr::kable(digits=3)\n###linear model to predict life expectancy using gdp\nlm2=lm(life_expectancy~gdp,data=y_2000)\ntable2=broom::tidy(lm2)%>%\n  knitr::kable(digits=3)\ntable1\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n76.075\n3.348\n22.720\n0\n\n\nfertility\n-3.823\n0.625\n-6.113\n0\n\n\n\n\ntable2\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n55.014\n1.247\n44.106\n0.000\n\n\ngdp\n0.000\n0.000\n2.516\n0.015"
  },
  {
    "objectID": "coding_exercise.html#section-9",
    "href": "coding_exercise.html#section-9",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Based on the p-values of the linear models, a conclusion can be made that there is a statistical relationship between life expectancy and infant mortality but not life expectancy and population. ###this section is added by Weifan based on the p_values of two models, we can conclude that life expectancy can be predicted by both variables (fertility and GDP)"
  },
  {
    "objectID": "coding_exercise.html#section-10",
    "href": "coding_exercise.html#section-10",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Based on the p-values of the linear models, a conclusion can be made that there is a statistical relationship between life expectancy and infant mortality but not life expectancy and population. ###this section is added by Weifan based on the p_values of two models, we can conclude that life expectancy can be predicted by both variables (fertility and GDP)"
  },
  {
    "objectID": "dataanalysis_exercise.html",
    "href": "dataanalysis_exercise.html",
    "title": "Data Analysis Exercise",
    "section": "",
    "text": "This data set contains the deaths involving COVID-19, pneumonia, and influenza reported to NCHS by sex, age group, and jurisdiction\n\n\nThis data was obtained from the Centers for Disease Control and Prevention (CDC)’s National Center for Health Statistics (NCHS).\n\n\n\nThis dataset contains 116,000 rows and 16 columns."
  },
  {
    "objectID": "dataanalysis_exercise.html#load-libraries",
    "href": "dataanalysis_exercise.html#load-libraries",
    "title": "Data Analysis Exercise",
    "section": "Load Libraries",
    "text": "Load Libraries\n\n\nLoading required package: ggplot2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n✔ purrr   1.0.1      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nLoading required package: timechange\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union"
  },
  {
    "objectID": "dataanalysis_exercise.html#load-data",
    "href": "dataanalysis_exercise.html#load-data",
    "title": "Data Analysis Exercise",
    "section": "Load Data",
    "text": "Load Data\n\nRaw_Data <- read_csv(\"dataanalysis-exercise/data/Provisional_COVID-19_Deaths_by_Sex_and_Age.csv\")\n\nRows: 115668 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Data As Of, Start Date, End Date, Group, State, Sex, Age Group, Foo...\ndbl (8): Year, Month, COVID-19 Deaths, Total Deaths, Pneumonia Deaths, Pneum...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "dataanalysis_exercise.html#data-contents-1",
    "href": "dataanalysis_exercise.html#data-contents-1",
    "title": "Data Analysis Exercise",
    "section": "Data Contents",
    "text": "Data Contents\n\nstr(Raw_Data)\n\nspc_tbl_ [115,668 × 16] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Data As Of                              : chr [1:115668] \"01/25/2023\" \"01/25/2023\" \"01/25/2023\" \"01/25/2023\" ...\n $ Start Date                              : chr [1:115668] \"01/01/2020\" \"01/01/2020\" \"01/01/2020\" \"01/01/2020\" ...\n $ End Date                                : chr [1:115668] \"01/21/2023\" \"01/21/2023\" \"01/21/2023\" \"01/21/2023\" ...\n $ Group                                   : chr [1:115668] \"By Total\" \"By Total\" \"By Total\" \"By Total\" ...\n $ Year                                    : num [1:115668] NA NA NA NA NA NA NA NA NA NA ...\n $ Month                                   : num [1:115668] NA NA NA NA NA NA NA NA NA NA ...\n $ State                                   : chr [1:115668] \"United States\" \"United States\" \"United States\" \"United States\" ...\n $ Sex                                     : chr [1:115668] \"All Sexes\" \"All Sexes\" \"All Sexes\" \"All Sexes\" ...\n $ Age Group                               : chr [1:115668] \"All Ages\" \"Under 1 year\" \"0-17 years\" \"1-4 years\" ...\n $ COVID-19 Deaths                         : num [1:115668] 1098594 413 1446 227 444 ...\n $ Total Deaths                            : num [1:115668] 10215767 59245 105422 11382 17721 ...\n $ Pneumonia Deaths                        : num [1:115668] 1036445 798 2258 496 643 ...\n $ Pneumonia and COVID-19 Deaths           : num [1:115668] 551596 68 367 54 129 ...\n $ Influenza Deaths                        : num [1:115668] 19209 49 367 116 165 ...\n $ Pneumonia, Influenza, or COVID-19 Deaths: num [1:115668] 1600437 1190 3688 780 1115 ...\n $ Footnote                                : chr [1:115668] NA NA NA NA ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   `Data As Of` = col_character(),\n  ..   `Start Date` = col_character(),\n  ..   `End Date` = col_character(),\n  ..   Group = col_character(),\n  ..   Year = col_double(),\n  ..   Month = col_double(),\n  ..   State = col_character(),\n  ..   Sex = col_character(),\n  ..   `Age Group` = col_character(),\n  ..   `COVID-19 Deaths` = col_double(),\n  ..   `Total Deaths` = col_double(),\n  ..   `Pneumonia Deaths` = col_double(),\n  ..   `Pneumonia and COVID-19 Deaths` = col_double(),\n  ..   `Influenza Deaths` = col_double(),\n  ..   `Pneumonia, Influenza, or COVID-19 Deaths` = col_double(),\n  ..   Footnote = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr>"
  },
  {
    "objectID": "dataanalysis_exercise.html#determine-what-data-to-keep",
    "href": "dataanalysis_exercise.html#determine-what-data-to-keep",
    "title": "Data Analysis Exercise",
    "section": "Determine what data to keep",
    "text": "Determine what data to keep\n\ndfm = data %>% pivot_longer(cols=c('COVID_19_Deaths','Pneumonia_Deaths','Influenza_Deaths'),\n                    names_to=\"variable\",\n                    values_to=\"value\")\nyear_plot = ggplot(dfm,aes(x = Year,y = value)) + \n    geom_bar(aes(fill = variable),stat = \"identity\",position = \"dodge\")+theme(legend.position = \"bottom\",legend.key.width= unit(0.1, 'cm'), legend.title= element_blank(),axis.text.x=element_text(size=9))\n\nage_plot = ggplot(dfm,aes(x = Age_Group,y = value)) + \n    geom_bar(aes(fill = variable),stat = \"identity\",position = \"dodge\")+theme(legend.position=\"none\",axis.text.x = element_text(size = 10, angle=60, hjust=1))\n\n\nyear_plot\n\nWarning: Removed 91149 rows containing missing values (`geom_bar()`).\n\n\n\n\nage_plot\n\nWarning: Removed 91149 rows containing missing values (`geom_bar()`).\n\n\n\n\n\nAccording to the footnotes column, there are multiple data points that had been suppressed due to NCHS confidentiality standards. Separated by state and/or age have many points that have been suppressed. The best option is to subset the data by year, and keep only rows containing all ages, and states.\nSubset to keep\ncollected in 2020 and 2021\n\nclean_data = data %>% filter(State == \"United States\",Age_Group==\"All Ages\",Year == 2020 | Year == 2021, Sex == \"All Sexes\")%>%\n  select(Start_Date, End_Date, COVID_19_Deaths,Pneumonia_Deaths,Influenza_Deaths, Group, Sex, Year)\n\n\nclean_data\n\n# A tibble: 26 × 8\n   Start_Date End_Date   COVID_19_Deaths Pneumonia_D…¹ Influ…² Group Sex   Year \n   <date>     <date>               <dbl>         <dbl>   <dbl> <chr> <chr> <chr>\n 1 2020-01-01 2020-12-31          385666        352010    8787 By Y… All … 2020 \n 2 2021-01-01 2021-12-31          463199        412020    1092 By Y… All … 2021 \n 3 2020-01-01 2020-01-31               6         17909    2125 By M… All … 2020 \n 4 2020-02-01 2020-02-29              25         15740    2373 By M… All … 2020 \n 5 2020-03-01 2020-03-31            7174         22479    2437 By M… All … 2020 \n 6 2020-04-01 2020-04-30           65550         46427    1237 By M… All … 2020 \n 7 2020-05-01 2020-05-31           38329         29010     126 By M… All … 2020 \n 8 2020-06-01 2020-06-30           18026         19294      40 By M… All … 2020 \n 9 2020-07-01 2020-07-31           31135         27121      50 By M… All … 2020 \n10 2020-08-01 2020-08-31           29911         27358      43 By M… All … 2020 \n# … with 16 more rows, and abbreviated variable names ¹​Pneumonia_Deaths,\n#   ²​Influenza_Deaths"
  },
  {
    "objectID": "tidytuesday_exercise.html#add-data",
    "href": "tidytuesday_exercise.html#add-data",
    "title": "Tidy Tuesday Exercise",
    "section": "Add Data",
    "text": "Add Data\n\nage_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')\n\nRows: 1155 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): movie_name, director, actor_1_name, actor_2_name, character_1_gend...\ndbl  (5): release_year, age_difference, couple_number, actor_1_age, actor_2_age\ndate (2): actor_1_birthdate, actor_2_birthdate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "tidytuesday_exercise.html#clean-and-explore-the-data",
    "href": "tidytuesday_exercise.html#clean-and-explore-the-data",
    "title": "Tidy Tuesday Exercise",
    "section": "Clean and Explore the data",
    "text": "Clean and Explore the data\n\nglimpse(age_gaps)\n\nRows: 1,155\nColumns: 13\n$ movie_name         <chr> \"Harold and Maude\", \"Venus\", \"The Quiet American\", …\n$ release_year       <dbl> 1971, 2006, 2002, 1998, 2010, 1992, 2009, 1999, 199…\n$ director           <chr> \"Hal Ashby\", \"Roger Michell\", \"Phillip Noyce\", \"Joe…\n$ age_difference     <dbl> 52, 50, 49, 45, 43, 42, 40, 39, 38, 38, 36, 36, 35,…\n$ couple_number      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ actor_1_name       <chr> \"Ruth Gordon\", \"Peter O'Toole\", \"Michael Caine\", \"D…\n$ actor_2_name       <chr> \"Bud Cort\", \"Jodie Whittaker\", \"Do Thi Hai Yen\", \"T…\n$ character_1_gender <chr> \"woman\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", …\n$ character_2_gender <chr> \"man\", \"woman\", \"woman\", \"woman\", \"man\", \"woman\", \"…\n$ actor_1_birthdate  <date> 1896-10-30, 1932-08-02, 1933-03-14, 1930-09-17, 19…\n$ actor_2_birthdate  <date> 1948-03-29, 1982-06-03, 1982-10-01, 1975-11-08, 19…\n$ actor_1_age        <dbl> 75, 74, 69, 68, 81, 59, 62, 69, 57, 77, 59, 56, 65,…\n$ actor_2_age        <dbl> 23, 24, 20, 23, 38, 17, 22, 30, 19, 39, 23, 20, 30,…\n\n\n\n#Change the column order \nage_gaps = age_gaps %>%\n  relocate(actor_1_birthdate,actor_1_age,character_1_gender, .after = actor_1_name) %>%\n  relocate(actor_2_birthdate,actor_2_age,character_2_gender, .after = actor_2_name)%>%\n  relocate(couple_number, .before = age_difference)\n\n\nTable displaying the data\n\nhead(age_gaps) %>% \n  gt() %>%\n  tab_header(\n    title = \"Tidy Tuesday - Hollywood Age Gaps\",\n    subtitle = \"Reformated\"\n  )%>% \n tab_style(\n     locations = cells_title(groups = \"title\"),\n     style     = list(\n       cell_text(weight = \"bold\", size = 24)\n     ))\n\n\n\n\n\n  \n    \n      Tidy Tuesday - Hollywood Age Gaps\n    \n    \n      Reformated\n    \n  \n  \n    \n      movie_name\n      release_year\n      director\n      couple_number\n      age_difference\n      actor_1_name\n      actor_1_birthdate\n      actor_1_age\n      character_1_gender\n      actor_2_name\n      actor_2_birthdate\n      actor_2_age\n      character_2_gender\n    \n  \n  \n    Harold and Maude\n1971\nHal Ashby\n1\n52\nRuth Gordon\n1896-10-30\n75\nwoman\nBud Cort\n1948-03-29\n23\nman\n    Venus\n2006\nRoger Michell\n1\n50\nPeter O'Toole\n1932-08-02\n74\nman\nJodie Whittaker\n1982-06-03\n24\nwoman\n    The Quiet American\n2002\nPhillip Noyce\n1\n49\nMichael Caine\n1933-03-14\n69\nman\nDo Thi Hai Yen\n1982-10-01\n20\nwoman\n    The Big Lebowski\n1998\nJoel Coen\n1\n45\nDavid Huddleston\n1930-09-17\n68\nman\nTara Reid\n1975-11-08\n23\nwoman\n    Beginners\n2010\nMike Mills\n1\n43\nChristopher Plummer\n1929-12-13\n81\nman\nGoran Visnjic\n1972-09-09\n38\nman\n    Poison Ivy\n1992\nKatt Shea\n1\n42\nTom Skerritt\n1933-08-25\n59\nman\nDrew Barrymore\n1975-02-22\n17\nwoman\n  \n  \n  \n\n\n\n\n\n\nNumeric Data Summary\n\n#numeric data summary\nnumeric_summary=skim(age_gaps,where(is.numeric))\nnumeric_summary = data.frame(numeric_summary)\n\n#Display as a table \n(numeric_summary) %>% \n  gt() %>%\n  tab_header(\n    title = \"Numeric Data Summary\"\n  )%>% \n tab_style(\n     locations = cells_title(groups = \"title\"),\n     style     = list(\n       cell_text(weight = \"bold\", size = 24)\n     ))\n\n\n\n\n\n  \n    \n      Numeric Data Summary\n    \n    \n  \n  \n    \n      skim_type\n      skim_variable\n      n_missing\n      complete_rate\n      numeric.mean\n      numeric.sd\n      numeric.p0\n      numeric.p25\n      numeric.p50\n      numeric.p75\n      numeric.p100\n      numeric.hist\n    \n  \n  \n    numeric\nrelease_year\n0\n1\n2000.799134\n16.3658191\n1935\n1997\n2004\n2012\n2022\n▁▁▁▆▇\n    numeric\ncouple_number\n0\n1\n1.398268\n0.7544188\n1\n1\n1\n2\n7\n▇▁▁▁▁\n    numeric\nage_difference\n0\n1\n10.424242\n8.5110857\n0\n4\n8\n15\n52\n▇▃▂▁▁\n    numeric\nactor_1_age\n0\n1\n40.635498\n10.4241730\n18\n33\n39\n47\n81\n▂▇▅▂▁\n    numeric\nactor_2_age\n0\n1\n30.211255\n7.4959523\n17\n25\n29\n34\n68\n▇▇▂▁▁\n  \n  \n  \n\n\n\n\n\n\nDetermine the age range difference and the count of occurences as a table\n\n#find the frequency of unique age gap values\nageRange = as.data.frame(table(age_gaps$age_difference)) \n#rename Var1 to Age_Gap\nageRange = rename(ageRange, Age_Gap = Var1)\n#ageRange = ageRange %>% arrange(desc(Freq))\n\n#create table based on the frequence\nageRange_Table = ageRange%>% \n  gt()%>% \ncols_label(\n   Age_Gap = md(\"**Age Gap**\"),\n   Freq = md(\"**Freq**\")\n  )%>% \n  tab_header(\n    title = \"Age Gap Frequency\",\n  )%>% \n tab_style(\n     locations = cells_title(groups = \"title\"),\n     style     = list(\n       cell_text(weight = \"bold\", size = 24)\n     ))\n\n#heat map of the frequencies\nminfreq = min(ageRange$Freq)\nmaxfreq = max(ageRange$Freq)\nageGap_Pallet = col_numeric(c(\"#FEF0D9\", \"#990000\"), domain = c(minfreq, maxfreq), alpha = 0.75)\n\n(ageRange_Table = ageRange_Table %>% \n    data_color(columns = c(Freq),\n               colors = ageGap_Pallet))\n\n\n\n\n\n  \n    \n      Age Gap Frequency\n    \n    \n  \n  \n    \n      Age Gap\n      Freq\n    \n  \n  \n    0\n30\n    1\n77\n    2\n85\n    3\n85\n    4\n66\n    5\n71\n    6\n50\n    7\n71\n    8\n59\n    9\n52\n    10\n45\n    11\n51\n    12\n36\n    13\n37\n    14\n31\n    15\n22\n    16\n33\n    17\n30\n    18\n30\n    19\n21\n    20\n20\n    21\n25\n    22\n11\n    23\n13\n    24\n15\n    25\n18\n    26\n10\n    27\n6\n    28\n10\n    29\n8\n    30\n8\n    31\n2\n    32\n6\n    33\n3\n    34\n4\n    35\n2\n    36\n2\n    38\n2\n    39\n1\n    40\n1\n    42\n1\n    43\n1\n    45\n1\n    49\n1\n    50\n1\n    52\n1\n  \n  \n  \n\n\n\n\nWe can see from this table that smaller age gaps are more frequent than larger age gaps. Lets visualize this data as a bar plot\n\nage_bar = ggplot(ageRange, aes(x = Age_Gap, y = Freq)) +\n  geom_col(width = 0.3,color=\"blue\") + theme(axis.text.x = element_text(face=\"bold\", \n                           size=8, angle=45)) + xlab(\"Age Gap (Years)\") + ylab(\"Frequency\") +ggtitle(\"Age Gap Frequency\") +theme(\n  plot.title = element_text(color=\"Black\", size=14, face=\"bold\"))\nggplotly(age_bar)\n\n\n\n\n\nAs the age increases, the frequency decreases.\n##Sex distribution of the the older and younger actors\n\n#find the frequency of unique age gap values\nactor1Freq = as.data.frame(table(age_gaps$character_1_gender)) \n#rename Var1 to Age_Gap\nactor1Freq = rename(actor1Freq, Sex = Var1)\n\n#create table based on the frequence\nactor1_Table = actor1Freq%>% \n  gt()%>% \ncols_label(\n   Sex = md(\"**Sex**\"),\n   Freq = md(\"**Freq**\")\n  )%>% \n  tab_header(\n    title = \"Actor 1 Frequency\",\n  )%>% \n tab_style(\n     locations = cells_title(groups = \"title\"),\n     style     = list(\n       cell_text(weight = \"bold\", size = 24)\n     ))\n\n#find the frequency of unique age gap values\nactor2Freq = as.data.frame(table(age_gaps$character_2_gender)) \n#rename Var1 to Age_Gap\nactor2Freq = rename(actor2Freq, Sex = Var1)\n\n#create table based on the frequency\nactor2_Table = actor2Freq%>% \n  gt()%>% \ncols_label(\n   Sex = md(\"**Sex**\"),\n   Freq = md(\"**Freq**\")\n  )%>% \n  tab_header(\n    title = \"Actor 2 Frequency\",\n  )%>% \n tab_style(\n     locations = cells_title(groups = \"title\"),\n     style     = list(\n       cell_text(weight = \"bold\", size = 24)\n     ))\n\n\nactor1Freq %>%\n  kable(\"html\", align = 'clc') %>%\n    kable_styling(full_width = F, position = \"float_left\")\nactor2Freq %>%\n  kable(\"html\", align = 'clc') %>%\n    kable_styling(full_width = F, position = \"right\")\n\n\nCharacter Sex Frequency Tables\n\n\n\n\nActor 1 \n \n  \n    Sex \n    Freq \n  \n \n\n  \n    man \n    941 \n  \n  \n    woman \n    214 \n  \n\n\n\n\n\n\nActor 2 \n \n  \n    Sex \n    Freq \n  \n \n\n  \n    man \n    215 \n  \n  \n    woman \n    940 \n  \n\n\n\n\n\n\n\n\n\nThere are more male older actors and than female. How does the age gap differ?\n\nggplot(age_gaps, aes(x=character_1_gender, y=age_difference,color=character_1_gender)) +geom_point() + \n  geom_line() + geom_boxplot()+ggtitle(\"Actor 1\") +theme(\n  plot.title = element_text(color=\"Black\", size=14, face=\"bold\"))\n\n\n\n\n**There is a larger age gap for male actors who are older than their partner than female actors who are older.\n###There are more female younger actors and than male How does the age gap differ?\n\nggplot(age_gaps, aes(x=character_2_gender, y=age_difference,color=character_2_gender)) +geom_point() + \n  geom_line() + geom_boxplot()+ geom_boxplot()+ggtitle(\"Actor 2\") +theme(\n  plot.title = element_text(color=\"Black\", size=14, face=\"bold\"))\n\n\n\n\n###Max Age difference by year\n\n#plot the max age difference each year over the years \nMax = age_gaps %>%\n  group_by(release_year) %>%\n  summarise(max = max(age_difference))\n\nggplot(Max, aes(x = release_year, y = max)) +\n  geom_line()+geom_smooth(method = \"loess\", color = \"red\", fill = \"red\")+ggtitle(\"Max Age difference by year\") +theme(\n  plot.title = element_text(color=\"Black\", size=14, face=\"bold\"))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nAverage age difference by year\n\n#plot the average age difference over the years \n\nAverageTable = age_gaps %>%\n  group_by(release_year) %>%\n  summarise(average = mean(age_difference))\n\nggplot(AverageTable, aes(x = release_year, y = average)) +\n  geom_line()+geom_smooth(method = \"loess\", color = \"red\", fill = \"red\")+ggtitle(\"Average Age difference by year\") +theme(\n  plot.title = element_text(color=\"Black\", size=14, face=\"bold\"))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThere were alot more movies created in the later years so this may not be a great representation of the data set and age gaps over time.\n\n\nDo certain directors cast actors with larger age gaps?\nDirectors who cast with smaller age gaps\n\nd_small=age_gaps%>%\n  select(director,age_difference)%>%\n  filter(age_difference<25)%>%\n  count(director)%>%\n  arrange(desc(n))%>%\n  filter(n>1)\nnrow(d_small)\n\n[1] 245\n\n#create table\nd_small_Table = head(d_small)%>% \n  gt()%>% \ncols_label(\n   director = md(\"**Director**\"),\n   n = md(\"**Freq**\")\n  )%>% \n  tab_header(\n    title = \"Directors who cast small age gaps\",\n    subtitle = \"This table lists the head of the table of directors who cast actors in a movie with an age gap smaller than to 25 years at least 3 times\"\n  )%>% \n tab_style(\n     locations = cells_title(groups = \"title\"),\n     style     = list(\n       cell_text(weight = \"bold\", size = 24)\n     )) %>%\n  tab_source_note(\n    source_note = \"There are a total of 245 directors who cast at least 2 movies with age gaps below 25 years of age\"\n  )\n\nd_small_Table\n\n\n\n\n\n  \n    \n      Directors who cast small age gaps\n    \n    \n      This table lists the head of the table of directors who cast actors in a movie with an age gap smaller than to 25 years at least 3 times\n    \n  \n  \n    \n      Director\n      Freq\n    \n  \n  \n    Woody Allen\n12\n    John Glen\n11\n    Martin Scorsese\n11\n    Mike Newell\n10\n    Dennis Dugan\n9\n    Guy Hamilton\n9\n  \n  \n    \n      There are a total of 245 directors who cast at least 2 movies with age gaps below 25 years of age\n    \n  \n  \n\n\n\ndSmall_concat=inner_join(age_gaps,d_small,by=\"director\")\n\nDirectors who cast with larger age gaps (only ones with more than 1)\n\nd_large=age_gaps%>%\n  select(director,age_difference)%>%\n  filter(age_difference>=25)%>%\n  count(director)%>%\n  arrange(desc(n))%>%\n  filter(n>1)\nd_large\n\n# A tibble: 12 × 2\n   director                 n\n   <chr>                <int>\n 1 Woody Allen              8\n 2 John Glen                4\n 3 John Huston              3\n 4 Adrian Lyne              2\n 5 Alfred Hitchcock         2\n 6 Howard Hawks             2\n 7 Joel Coen                2\n 8 Martin Scorsese          2\n 9 Paul Thomas Anderson     2\n10 Roger Michell            2\n11 Scott Cooper             2\n12 Stanley Donen            2\n\ndLarge_concat=inner_join(age_gaps,d_large,by=\"director\")\n\n#create table\nd_large_Table = d_large%>% \n  gt()%>% \ncols_label(\n   director = md(\"**Director**\"),\n   n = md(\"**Freq**\")\n  )%>% \n  tab_header(\n    title = \"Directors with large age gaps\",\n    subtitle = \"This table lists the directors who cast actors in a movie with an aga gap greater than or equal to 25 at least 2 times\"\n  )%>% \n tab_style(\n     locations = cells_title(groups = \"title\"),\n     style     = list(\n       cell_text(weight = \"bold\", size = 24)\n     ))\n\nd_large_Table\n\n\n\n\n\n  \n    \n      Directors with large age gaps\n    \n    \n      This table lists the directors who cast actors in a movie with an aga gap greater than or equal to 25 at least 2 times\n    \n  \n  \n    \n      Director\n      Freq\n    \n  \n  \n    Woody Allen\n8\n    John Glen\n4\n    John Huston\n3\n    Adrian Lyne\n2\n    Alfred Hitchcock\n2\n    Howard Hawks\n2\n    Joel Coen\n2\n    Martin Scorsese\n2\n    Paul Thomas Anderson\n2\n    Roger Michell\n2\n    Scott Cooper\n2\n    Stanley Donen\n2\n  \n  \n  \n\n\n\n\n\np = plot_ly(dLarge_concat, x = ~director, y = ~age_difference,\n             type = \"scatter\", mode = 'markers', marker = list(color = \"blue\"), \n             text =~paste('</br> Director: ', director,\n                      '</br> Movie: ', movie_name,\n                      '</br> Age Gap: ', age_difference),\n             hoverinfo = \"text\")\np = p  %>% layout (title = \"Directors with age gaps over 25 years and their movies\",xaxis = list(title = \"Director\"), yaxis = list(title = \"Age Gap\"))\np"
  },
  {
    "objectID": "fluanalysis/code/wrangling.html",
    "href": "fluanalysis/code/wrangling.html",
    "title": "Flu Anlaysis - Wrangling",
    "section": "",
    "text": "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.1     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nhere() starts at /Users/deannalanier/Desktop/All_Classes_UGA/2023Spr_Classes/MADA/deannalanier-MADA-portfolio\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.3\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.4     ✔ yardstick    1.1.0\n✔ recipes      1.0.5     \n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\n\n\n\n\n\nraw_data = readRDS(here(\"fluanalysis\", \"data\", \"SympAct_Any_Pos.Rda\")) #load RDS file\n\n\n\n\n\nstr(raw_data) #ensure the data is complete\n\n'data.frame':   735 obs. of  63 variables:\n $ DxName1          : Factor w/ 92 levels \"Acute bronchitis, unspecified\",..: 57 16 57 57 9 57 39 17 57 57 ...\n $ DxName2          : Factor w/ 142 levels \"14 weeks gestation of pregnancy\",..: NA 69 11 129 69 NA 69 60 12 NA ...\n $ DxName3          : Factor w/ 92 levels \"Abnormal weight loss\",..: NA NA NA NA NA NA NA NA 38 NA ...\n $ DxName4          : Factor w/ 41 levels \"Acute bronchitis, unspecified\",..: NA NA NA NA NA NA NA NA 30 NA ...\n $ DxName5          : Factor w/ 5 levels \"Acute suppurative otitis media without spontaneous rupture of ear drum, right ear\",..: NA NA NA NA NA NA NA NA 3 NA ...\n $ Unique.Visit     : chr  \"340_17632125\" \"340_17794836\" \"342_17737773\" \"342_17806002\" ...\n $ ActivityLevel    : int  10 6 2 2 5 3 4 0 0 5 ...\n  ..- attr(*, \"label\")= chr \"Activity Level\"\n $ ActivityLevelF   : Factor w/ 11 levels \"0\",\"1\",\"2\",\"3\",..: 11 7 3 3 6 4 5 1 1 6 ...\n $ SwollenLymphNodes: Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 1 1 1 2 1 ...\n  ..- attr(*, \"label\")= chr \"Swollen Lymph Nodes\"\n $ ChestCongestion  : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 1 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Chest Congestion\"\n $ ChillsSweats     : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 2 2 2 1 ...\n  ..- attr(*, \"label\")= chr \"Chills/Sweats\"\n $ NasalCongestion  : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 1 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Nasal Congestion\"\n $ CoughYN          : Factor w/ 2 levels \"No\",\"Yes\": 2 2 1 2 1 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Cough\"\n $ Sneeze           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 1 2 1 2 1 1 ...\n  ..- attr(*, \"label\")= chr \"Sneeze\"\n $ Fatigue          : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Fatigue\"\n $ SubjectiveFever  : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 1 ...\n  ..- attr(*, \"label\")= chr \"Subjective Fever\"\n $ Headache         : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Headache\"\n $ Weakness         : Factor w/ 4 levels \"None\",\"Mild\",..: 2 4 4 4 3 3 2 4 3 3 ...\n $ WeaknessYN       : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Weakness\"\n $ CoughIntensity   : Factor w/ 4 levels \"None\",\"Mild\",..: 4 4 2 3 1 3 4 3 3 3 ...\n  ..- attr(*, \"label\")= chr \"Cough Severity\"\n $ CoughYN2         : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 2 2 2 2 ...\n $ Myalgia          : Factor w/ 4 levels \"None\",\"Mild\",..: 2 4 4 4 2 3 2 4 3 2 ...\n $ MyalgiaYN        : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Myalgia\"\n $ RunnyNose        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 1 1 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Runny Nose\"\n $ AbPain           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Abdominal Pain\"\n $ ChestPain        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 2 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Chest Pain\"\n $ Diarrhea         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 2 1 1 1 1 ...\n $ EyePn            : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 2 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Eye Pain\"\n $ Insomnia         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Sleeplessness\"\n $ ItchyEye         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Itchy Eyes\"\n $ Nausea           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 1 1 2 2 ...\n $ EarPn            : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Ear Pain\"\n $ Hearing          : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Loss of Hearing\"\n $ Pharyngitis      : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Sore Throat\"\n $ Breathless       : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 2 1 1 1 2 ...\n  ..- attr(*, \"label\")= chr \"Breathlessness\"\n $ ToothPn          : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 1 1 2 1 ...\n  ..- attr(*, \"label\")= chr \"Tooth Pain\"\n $ Vision           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Blurred Vision\"\n $ Vomit            : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Vomiting\"\n $ Wheeze           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 2 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Wheezing\"\n $ BodyTemp         : num  98.3 100.4 100.8 98.8 100.5 ...\n $ RapidFluA        : Factor w/ 2 levels \"Positive for Influenza A\",..: 2 NA 2 2 NA NA NA 1 2 2 ...\n $ RapidFluB        : Factor w/ 2 levels \"Positive for Influenza B\",..: 2 NA 2 2 NA NA NA 2 2 2 ...\n $ PCRFluA          : Factor w/ 4 levels \" Influenza A Detected\",..: NA NA NA NA NA NA 2 NA NA NA ...\n $ PCRFluB          : Factor w/ 3 levels \" Influenza B Detected\",..: NA NA NA NA NA NA 2 NA NA NA ...\n $ TransScore1      : num  1 3 4 5 0 2 2 5 4 4 ...\n $ TransScore1F     : Factor w/ 6 levels \"0\",\"1\",\"2\",\"3\",..: 2 4 5 6 1 3 3 6 5 5 ...\n  ..- attr(*, \"label\")= chr \"Infectiousness Score\"\n $ TransScore2      : num  1 2 3 4 0 2 2 4 3 3 ...\n $ TransScore2F     : Factor w/ 5 levels \"0\",\"1\",\"2\",\"3\",..: 2 3 4 5 1 3 3 5 4 4 ...\n  ..- attr(*, \"label\")= chr \"Infectiousness Score\"\n $ TransScore3      : num  1 1 2 3 0 2 2 3 2 2 ...\n $ TransScore3F     : Factor w/ 4 levels \"0\",\"1\",\"2\",\"3\": 2 2 3 4 1 3 3 4 3 3 ...\n  ..- attr(*, \"label\")= chr \"Infectiousness Score\"\n $ TransScore4      : num  0 2 4 4 0 1 1 4 3 3 ...\n $ TransScore4F     : Factor w/ 5 levels \"0\",\"1\",\"2\",\"3\",..: 1 3 5 5 1 2 2 5 4 4 ...\n $ ImpactScore      : int  7 8 14 12 11 12 8 7 10 7 ...\n $ ImpactScore2     : int  6 7 13 11 10 11 7 6 9 6 ...\n $ ImpactScore3     : int  3 4 9 7 6 7 3 3 6 4 ...\n $ ImpactScoreF     : Factor w/ 21 levels \"0\",\"1\",\"2\",\"3\",..: 8 9 15 13 12 13 9 8 11 8 ...\n  ..- attr(*, \"label\")= chr \"Morbidity Score\"\n $ ImpactScore2F    : Factor w/ 19 levels \"0\",\"1\",\"2\",\"3\",..: 7 8 14 12 11 12 8 7 10 7 ...\n  ..- attr(*, \"label\")= chr \"Morbidity Score\"\n $ ImpactScore3F    : Factor w/ 15 levels \"0\",\"1\",\"2\",\"3\",..: 4 5 10 8 7 8 4 4 7 5 ...\n  ..- attr(*, \"label\")= chr \"Morbidity Score\"\n $ ImpactScoreFD    : Factor w/ 17 levels \"2\",\"3\",\"4\",\"5\",..: 6 7 13 11 10 11 7 6 9 6 ...\n $ TotalSymp1       : num  8 11 18 17 11 14 10 12 14 11 ...\n $ TotalSymp1F      : Factor w/ 19 levels \"5\",\"6\",\"7\",\"8\",..: 4 7 14 13 7 10 6 8 10 7 ...\n $ TotalSymp2       : num  8 10 17 16 11 14 10 11 13 10 ...\n $ TotalSymp3       : num  8 9 16 15 11 14 10 10 12 9 ...\n\n\n\n\n\n1. Remove all variables that have Score or Total or FluA or FluB or Dxname or Activity or Unique.Visit\n2. Remove all observations with NA\nDon’t do this manually one by one, figure out how to use R commands that let you remove things in an efficient manner.\n\nclean_data = raw_data %>% #create new variable to ensure raw_data is not manipulated\n  select(-contains(c(\"Score\",\"Total\",\"FluA\",\"FluB\",\"Dxname\",\"Activity\")))%>% #select columns to remove\n  select(-c('Unique.Visit')) %>% #remove collumn\n  na.omit() #remove all observations with NA\n\n\n\n\nremove yes/no versions for symptoms with multiple levels\n\nclean_data_update =\n  clean_data %>%\n  select(!c(WeaknessYN, CoughYN, MyalgiaYN, CoughYN2))\n\ncategorical/ordinal predictors there are categorical and ordinal predictors. Code categorical variables as unordered factors and others as ordered factors.\n\n# categorical productors \nunorderedRecipe = recipe(~ SwollenLymphNodes + ChestCongestion + ChillsSweats + NasalCongestion + Sneeze + Fatigue + SubjectiveFever + Headache + RunnyNose + AbPain + ChestPain + Diarrhea + EyePn + Insomnia + ItchyEye + Nausea + EarPn + Pharyngitis + Breathless + ToothPn + Vomit + Wheeze, data = clean_data_update)\n\nunorderedTest = unorderedRecipe %>%\n  step_dummy(all_predictors()) %>%\n  prep(training = clean_data_update)\n\ncategoricalTestData = bake(unorderedTest, new_data = NULL)\n\n\n#ordinal predictor\n\n#specify the ordinal levels as found in the data\nordinalLevels = c(\"None\", \"Mild\", \"Moderate\", \"Severe\")\nclean_data_update = clean_data_update %>%\n  mutate(Weakness = ordered(Weakness),\n         CoughIntensity = ordered(CoughIntensity),\n         Myalgia = ordered(Myalgia))\n\n#create recipe (like categorical above)\nordinalRecipe = recipe(~ Weakness + CoughIntensity + Myalgia, data = clean_data_update)\nordinalTest = ordinalRecipe %>%\n  step_ordinalscore(all_predictors()) %>%\n  prep(training = clean_data_update)\nordinalTestData <- bake(ordinalTest, new_data = NULL)\n\nidentify and remove binary predictors that have <50 entries in one category\n\nsummary(clean_data_update)\n\n SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion Sneeze   \n No :418           No :323         No :130      No :167         No :339  \n Yes:312           Yes:407         Yes:600      Yes:563         Yes:391  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Fatigue   SubjectiveFever Headache      Weakness    CoughIntensity\n No : 64   No :230         No :115   None    : 49   None    : 47   \n Yes:666   Yes:500         Yes:615   Mild    :223   Mild    :154   \n                                     Moderate:338   Moderate:357   \n                                     Severe  :120   Severe  :172   \n                                                                   \n                                                                   \n     Myalgia    RunnyNose AbPain    ChestPain Diarrhea  EyePn     Insomnia \n None    : 79   No :211   No :639   No :497   No :631   No :617   No :315  \n Mild    :213   Yes:519   Yes: 91   Yes:233   Yes: 99   Yes:113   Yes:415  \n Moderate:325                                                              \n Severe  :113                                                              \n                                                                           \n                                                                           \n ItchyEye  Nausea    EarPn     Hearing   Pharyngitis Breathless ToothPn  \n No :551   No :475   No :568   No :700   No :119     No :436    No :565  \n Yes:179   Yes:255   Yes:162   Yes: 30   Yes:611     Yes:294    Yes:165  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Vision    Vomit     Wheeze       BodyTemp     \n No :711   No :652   No :510   Min.   : 97.20  \n Yes: 19   Yes: 78   Yes:220   1st Qu.: 98.20  \n                               Median : 98.50  \n                               Mean   : 98.94  \n                               3rd Qu.: 99.30  \n                               Max.   :103.10  \n\n# vision and hearing have les than 50\n\nclean_data_update = \n  clean_data_update %>%\n  select(!c(Vision, Hearing))\n\n\n\n\n\n#save cleaned data\ncleandata_location = here(\"fluanalysis\", \"data\", \"cleandata.rds\")\nsaveRDS(clean_data, file = cleandata_location)\n\n\n# save cleaned data after Module 11\ncleandata_location2 = here(\"fluanalysis\", \"data\", \"cleandata2.rds\")\nsaveRDS(clean_data_update, file = cleandata_location2)"
  },
  {
    "objectID": "fluanalysis/code/exploration.html",
    "href": "fluanalysis/code/exploration.html",
    "title": "Flu Anlaysis - Exploration",
    "section": "",
    "text": "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.1     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nhere() starts at /Users/deannalanier/Desktop/All_Classes_UGA/2023Spr_Classes/MADA/deannalanier-MADA-portfolio\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout"
  },
  {
    "objectID": "fluanalysis/code/exploration.html#load-the-data",
    "href": "fluanalysis/code/exploration.html#load-the-data",
    "title": "Flu Anlaysis - Exploration",
    "section": "Load the data",
    "text": "Load the data\n\n#path to clean data\ndata = readRDS(here(\"fluanalysis\", \"data\", \"cleandata.rds\")) #load RDS file"
  },
  {
    "objectID": "fluanalysis/code/exploration.html#for-each-important-variable-produce-and-print-some-numerical-output-e.g.-a-table-or-some-summary-statistics-numbers.",
    "href": "fluanalysis/code/exploration.html#for-each-important-variable-produce-and-print-some-numerical-output-e.g.-a-table-or-some-summary-statistics-numbers.",
    "title": "Flu Anlaysis - Exploration",
    "section": "For each (important) variable, produce and print some numerical output (e.g. a table or some summary statistics numbers).",
    "text": "For each (important) variable, produce and print some numerical output (e.g. a table or some summary statistics numbers).\nSummary table of the Nausea column\n\n#Summary of Nausea\nnausea_summary = data%>% #nasea summary\n  pull(Nausea)%>%\n  summary()%>%\n  as.data.frame()%>%\n  rename(Freq = 1)\n#nausea_Data = data.frame(nausea_Data)\n\nnausea_summary%>%\ngt(rownames_to_stub = TRUE)%>%\ntab_header(\n  title = \"Flu Data Nausea Summary table\",\n  subtitle = \"Frequency of 'Yes' and 'No' Responses\"\n)%>% \n tab_style(\n     locations = cells_title(groups = \"title\"),\n     style     = list(\n       cell_text(weight = \"bold\", size = 24)\n     ))\n\n\n\n\n\n  \n    \n      Flu Data Nausea Summary table\n    \n    \n      Frequency of 'Yes' and 'No' Responses\n    \n  \n  \n    \n      \n      Freq\n    \n  \n  \n    No\n475\n    Yes\n255\n  \n  \n  \n\n\n\n\nSummary table of the body temperature column\n\nbodyTemp_summary = data%>% #bodyTemperature summary\n  pull(BodyTemp)%>%\n  as.data.frame()%>%\n  summary()%>%\n  as.data.frame() %>% \n  separate(Freq, c('Stat', 'Val'),\":\")%>% #separate summary statistics at \":\"\n  select( -c(1, 2)) #remove the first two empty rows\n\nbodyTemp_summary%>%\ngt(rownames_to_stub = TRUE)%>%\ntab_header(\n  title = \"Flu Data Body Temp Summary table\",\n  subtitle = \"Summary Statistics\"\n)%>% \n tab_style(\n     locations = cells_title(groups = \"title\"),\n     style     = list(\n       cell_text(weight = \"bold\", size = 24)\n     ))\n\n\n\n\n\n  \n    \n      Flu Data Body Temp Summary table\n    \n    \n      Summary Statistics\n    \n  \n  \n    \n      \n      Stat\n      Val\n    \n  \n  \n    1\nMin.   \n 97.20  \n    2\n1st Qu.\n 98.20  \n    3\nMedian \n 98.50  \n    4\nMean   \n 98.94  \n    5\n3rd Qu.\n 99.30  \n    6\nMax.   \n103.10"
  },
  {
    "objectID": "fluanalysis/code/exploration.html#for-each-important-continuous-variable-create-a-histogram-or-density-plot.",
    "href": "fluanalysis/code/exploration.html#for-each-important-continuous-variable-create-a-histogram-or-density-plot.",
    "title": "Flu Anlaysis - Exploration",
    "section": "For each (important) continuous variable, create a histogram or density plot.",
    "text": "For each (important) continuous variable, create a histogram or density plot.\nBody Temperature is the only continuous important variable.\n\n#Body Temperature Histogram\n\nannotation = data.frame(\n   x = c(100),\n   y = c(.5),\n   label = c(\"Mean\")\n)\n\np = data %>% ggplot(aes(x=BodyTemp)) + geom_histogram(aes(y=..density..), binwidth=0.2,color=\"black\", fill=\"gray\") + geom_density(alpha=.2,fill=\"#FF6666\") + geom_vline(aes(xintercept=mean(BodyTemp)),color=\"red\", linetype=\"dashed\", size=1) + geom_segment(aes(x = 99.8, y = .5, xend = 99, yend = .5), arrow = arrow(length = unit(0.5, \"cm\"))) + annotate(\"text\", x=100.1, y=0.5, label =\"Mean\")+ ggtitle(\"Body Temperature Density\") +\n  xlab(\"Temp\") + ylab(\"Density\")+ theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nggplotly(p)\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\nℹ The deprecated feature was likely used in the ggplot2 package.\n  Please report the issue at <\u001b]8;;https://github.com/tidyverse/ggplot2/issues\u0007https://github.com/tidyverse/ggplot2/issues\u001b]8;;\u0007>.\n\n\n\n\n\n\nhighest frequency/density is at 98.2(F)."
  },
  {
    "objectID": "fluanalysis/code/exploration.html#create-scatterplots-or-boxplots-or-similar-plots-for-the-variable-you-decided-is-your-main-outcome-of-interest-and-the-most-important-or-all-depending-on-number-of-variables-independent-variablespredictors.-for-this-dataset-you-can-pick-and-choose-a-few-predictor-variables.",
    "href": "fluanalysis/code/exploration.html#create-scatterplots-or-boxplots-or-similar-plots-for-the-variable-you-decided-is-your-main-outcome-of-interest-and-the-most-important-or-all-depending-on-number-of-variables-independent-variablespredictors.-for-this-dataset-you-can-pick-and-choose-a-few-predictor-variables.",
    "title": "Flu Anlaysis - Exploration",
    "section": "Create scatterplots or boxplots or similar plots for the variable you decided is your main outcome of interest and the most important (or all depending on number of variables) independent variables/predictors. For this dataset, you can pick and choose a few predictor variables.",
    "text": "Create scatterplots or boxplots or similar plots for the variable you decided is your main outcome of interest and the most important (or all depending on number of variables) independent variables/predictors. For this dataset, you can pick and choose a few predictor variables.\n\nThe firstirst outcome Interest is Body Temperature\n\n#create violin plots of the outcome of interest and important variables.\n\n\n#nausea and body temp\nnausea_plot = data %>% ggplot(aes(x=Nausea, y=BodyTemp,fill=Nausea)) + \n  geom_violin(trim=FALSE) + geom_boxplot(width=0.1, fill=\"white\")+ ggtitle(\"Body Temp and Nausea\")+scale_fill_brewer(palette=\"Dark2\")+theme_minimal()\n#nausea_plot\n\n#Cough and body temp\ncough_plot = data %>% ggplot(aes(x=CoughYN, y=BodyTemp,fill=CoughYN)) + \n  geom_violin(trim=FALSE) + geom_boxplot(width=0.1, fill=\"white\")+ ggtitle(\"Body Temp and Cough\")+scale_fill_brewer(palette=\"Dark2\")+theme_minimal()\n#cough_plot\n\n#Nasal Congestion and body temp\nnasal_plot = data %>% ggplot(aes(x=NasalCongestion, y=BodyTemp,fill=NasalCongestion)) + \n  geom_violin(trim=FALSE) + geom_boxplot(width=0.1, fill=\"white\")+ ggtitle(\"Body Temp and Congestion\")+scale_fill_brewer(palette=\"Dark2\")+theme_minimal()\n#nasal_plot\n\n#Runny nose and body temp\nnose_plot = data %>% ggplot(aes(x=RunnyNose, y=BodyTemp,fill=RunnyNose)) + \n  geom_violin(trim=FALSE) + geom_boxplot(width=0.1, fill=\"white\")+ ggtitle(\"Body Temp and Runny Nose\")+scale_fill_brewer(palette=\"Dark2\")+theme_minimal()\n#nose_plot\n\n\n#plot 2 on the sample plane\nggarrange(nausea_plot, cough_plot,\n          ncol = 2, nrow = 1, legend = \"bottom\")\n\n\n\n\n\n#plot the other two on the same plane\nggarrange(nose_plot, nasal_plot, ncol = 2, nrow = 1, legend = \"bottom\")\n\n\n\n\n\n\nSecond outcome interest is Nausea\n\n#bar plot of the outcome of interest and different variables\n\n\n#Nausea and Diarrhea bar plot\ndiarrhea_plot = data  %>% ggplot(aes(x=Nausea,fill = Diarrhea)) + geom_bar(width=0.5) + ggtitle(\"Nausea and Diarrhea\")+scale_fill_brewer(palette=\"Dark2\")+theme_minimal()\n#diarrhea_plot\n\n#Nausea and vomit bar plot\nvomit_plot = data  %>% ggplot(aes(x=Nausea,fill = Vomit)) + geom_bar(width=0.5) + ggtitle(\"Nausea and Vomit\")+scale_fill_brewer(palette=\"Dark2\") +theme_minimal()\n#vomit_plot\n\n\n# arrange plots on the same plane\nggarrange(diarrhea_plot, vomit_plot,\n          ncol = 2, nrow = 1, legend = \"bottom\")"
  },
  {
    "objectID": "fluanalysis/code/fitting.html#load-the-data",
    "href": "fluanalysis/code/fitting.html#load-the-data",
    "title": "Flu Anlaysis - Model Fitting",
    "section": "Load the data",
    "text": "Load the data\n\n#path to clean data\ndata = readRDS(here(\"fluanalysis\", \"data\", \"cleandata.rds\")) #load RDS file"
  },
  {
    "objectID": "fluanalysis/code/fitting.html#fit-a-linear-model-to-the-continuous-outcome-body-temperature-using-only-the-main-predictor-of-interest.",
    "href": "fluanalysis/code/fitting.html#fit-a-linear-model-to-the-continuous-outcome-body-temperature-using-only-the-main-predictor-of-interest.",
    "title": "Flu Anlaysis - Model Fitting",
    "section": "Fit a linear model to the continuous outcome (Body temperature) using only the main predictor of interest.",
    "text": "Fit a linear model to the continuous outcome (Body temperature) using only the main predictor of interest.\nOur main predictor is Runny Nose\n\n#specify linear model to regression model\nmodel1 = linear_reg() %>% \n  set_engine(\"lm\") \n\n#fit the linear model to our main predictor\nmodel_fit_1 = model1 %>% \n  fit(BodyTemp ~ RunnyNose, data=data)\n  model_fit_1\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = BodyTemp ~ RunnyNose, data = data)\n\nCoefficients:\n (Intercept)  RunnyNoseYes  \n     99.1431       -0.2926  \n\n\nTable of results #1\n\ntidy(model_fit_1) #table of model summary\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    99.1      0.0819   1210.   0      \n2 RunnyNoseYes   -0.293    0.0971     -3.01 0.00268\n\n\n#2\n\n#show results \nglance(model_fit_1)\n\n# A tibble: 1 × 12\n  r.squ…¹ adj.r…² sigma stati…³ p.value    df logLik   AIC   BIC devia…⁴ df.re…⁵\n    <dbl>   <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>   <int>\n1  0.0123  0.0110  1.19    9.08 0.00268     1 -1162. 2329. 2343.   1031.     728\n# … with 1 more variable: nobs <int>, and abbreviated variable names\n#   ¹​r.squared, ²​adj.r.squared, ³​statistic, ⁴​deviance, ⁵​df.residual\n\n\nPlot regression model as boxwhisker plot\n\ntidy(model_fit_1) %>% \n  dwplot(dot_args = list(size = 1, color = \"black\"),vline = geom_vline(xintercept = 0, colour = \"black\", linetype = 2),\n         whisker_args = list(color = \"blue\")) + xlab(\"Estimate\") + theme_minimal()\n\n\n\n\nRegression estimate for runny nose as a predictor is nearly -0.3\nplot performance\n\nmp1 = check_model(model_fit_1$fit)\n#model_1_performance\n\nAdjust the check_model output figure titles. This allows all the text on the axis to be legible.\n\n#mp1\np1 = plot(mp1)\n\n\n\np1[[1]] = p1[[1]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np1[[2]] = p1[[2]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np1[[3]] = p1[[3]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np1[[4]] = p1[[4]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np1[[5]] = p1[[5]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np1"
  },
  {
    "objectID": "fluanalysis/code/fitting.html#fits-another-linear-model-to-the-continuous-outcome-using-all-important-predictors-of-interest.",
    "href": "fluanalysis/code/fitting.html#fits-another-linear-model-to-the-continuous-outcome-using-all-important-predictors-of-interest.",
    "title": "Flu Anlaysis - Model Fitting",
    "section": "Fits another linear model to the continuous outcome using all (important) predictors of interest.",
    "text": "Fits another linear model to the continuous outcome using all (important) predictors of interest.\n\n#specify linear model to regression model\nmodel2 = linear_reg() %>% \n  set_engine(\"lm\") \n\n#fit the linear model to all predictors\nmodel_fit_2 = model2 %>% \n  fit(BodyTemp ~., data=data)\n  model_fit_2 #table of model summary\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = BodyTemp ~ ., data = data)\n\nCoefficients:\n           (Intercept)    SwollenLymphNodesYes      ChestCongestionYes  \n             97.925243               -0.165302                0.087326  \n       ChillsSweatsYes      NasalCongestionYes              CoughYNYes  \n              0.201266               -0.215771                0.313893  \n             SneezeYes              FatigueYes      SubjectiveFeverYes  \n             -0.361924                0.264762                0.436837  \n           HeadacheYes            WeaknessMild        WeaknessModerate  \n              0.011453                0.018229                0.098944  \n        WeaknessSevere           WeaknessYNYes      CoughIntensityMild  \n              0.373435                      NA                0.084881  \nCoughIntensityModerate    CoughIntensitySevere             CoughYN2Yes  \n             -0.061384               -0.037272                      NA  \n           MyalgiaMild         MyalgiaModerate           MyalgiaSevere  \n              0.164242               -0.024064               -0.129263  \n          MyalgiaYNYes            RunnyNoseYes               AbPainYes  \n                    NA               -0.080485                0.031574  \n          ChestPainYes             DiarrheaYes                EyePnYes  \n              0.105071               -0.156806                0.131544  \n           InsomniaYes             ItchyEyeYes               NauseaYes  \n             -0.006824               -0.008016               -0.034066  \n              EarPnYes              HearingYes          PharyngitisYes  \n              0.093790                0.232203                0.317581  \n         BreathlessYes              ToothPnYes               VisionYes  \n              0.090526               -0.022876               -0.274625  \n              VomitYes               WheezeYes  \n              0.165272               -0.046665  \n\n\nTable of model summary\n\ntidy(model_fit_2)#table of model summary\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic   p.value\n   <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)           97.9       0.304   322.     0        \n 2 SwollenLymphNodesYes  -0.165     0.0920   -1.80   0.0727   \n 3 ChestCongestionYes     0.0873    0.0975    0.895  0.371    \n 4 ChillsSweatsYes        0.201     0.127     1.58   0.114    \n 5 NasalCongestionYes    -0.216     0.114    -1.90   0.0584   \n 6 CoughYNYes             0.314     0.241     1.30   0.193    \n 7 SneezeYes             -0.362     0.0983   -3.68   0.000249 \n 8 FatigueYes             0.265     0.161     1.65   0.0996   \n 9 SubjectiveFeverYes     0.437     0.103     4.22   0.0000271\n10 HeadacheYes            0.0115    0.125     0.0913 0.927    \n# … with 28 more rows\n\n\nPlot regression model as boxwhisker plot\n\ntidy(model_fit_2) %>% \n  dwplot(dot_args = list(size = 1, color = \"black\"),vline = geom_vline(xintercept = 0, colour = \"black\", linetype = 2),\n         whisker_args = list(color = \"blue\")) + xlab(\"Estimate\") + theme_minimal()\n\n\n\n\nPlot performance\n\nmp2 = check_model(model_fit_2$fit)\n#model_1_performance\n\nAdjust the check_model output figure titles. This allows all the text on the axis to be legible.\n\np2 = plot(mp2)\n\n\n\np2[[1]] = p2[[1]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np2[[2]] = p2[[2]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np2[[3]] = p2[[3]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np2[[4]] = p2[[4]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np2[[5]] = p2[[5]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np2[[6]] = p2[[6]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np2"
  },
  {
    "objectID": "fluanalysis/code/fitting.html#compares-the-model-results-for-the-model-with-just-the-main-predictor-and-all-predictors.",
    "href": "fluanalysis/code/fitting.html#compares-the-model-results-for-the-model-with-just-the-main-predictor-and-all-predictors.",
    "title": "Flu Anlaysis - Model Fitting",
    "section": "Compares the model results for the model with just the main predictor and all predictors.",
    "text": "Compares the model results for the model with just the main predictor and all predictors.\n\ncompare_performance(model_fit_1,model_fit_2)\n\n# Comparison of Model Performance Indices\n\nName        | Model |  AIC (weights) | AICc (weights) |  BIC (weights) |    R2 | R2 (adj.) |  RMSE | Sigma\n----------------------------------------------------------------------------------------------------------\nmodel_fit_1 |   _lm | 2329.3 (<.001) | 2329.4 (<.001) | 2343.1 (>.999) | 0.012 |     0.011 | 1.188 | 1.190\nmodel_fit_2 |   _lm | 2303.8 (>.999) | 2307.7 (>.999) | 2469.2 (<.001) | 0.129 |     0.086 | 1.116 | 1.144"
  },
  {
    "objectID": "fluanalysis/code/fitting.html#fits-a-logistic-model-to-the-categorical-outcome-nausea-using-only-the-main-predictor-of-interest.",
    "href": "fluanalysis/code/fitting.html#fits-a-logistic-model-to-the-categorical-outcome-nausea-using-only-the-main-predictor-of-interest.",
    "title": "Flu Anlaysis - Model Fitting",
    "section": "Fits a logistic model to the categorical outcome (Nausea) using only the main predictor of interest.",
    "text": "Fits a logistic model to the categorical outcome (Nausea) using only the main predictor of interest.\n\n#specify linear model logistic_reg() which generalized linear model for binary outcomes\nmodel3 = logistic_reg() %>% \n  set_engine(\"glm\") #fit model generalized linear model \n\n#fit the linear model to our main predictor\nmodel_fit_3 = model3 %>% \n  fit(Nausea ~ RunnyNose, data=data)\n  model_fit_3 #table of model summary\n\nparsnip model object\n\n\nCall:  stats::glm(formula = Nausea ~ RunnyNose, family = stats::binomial, \n    data = data)\n\nCoefficients:\n (Intercept)  RunnyNoseYes  \n    -0.65781       0.05018  \n\nDegrees of Freedom: 729 Total (i.e. Null);  728 Residual\nNull Deviance:      944.7 \nResidual Deviance: 944.6    AIC: 948.6\n\n\nTable of results\n#1\n\ntidy(model_fit_3) #table of model summary\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic    p.value\n  <chr>           <dbl>     <dbl>     <dbl>      <dbl>\n1 (Intercept)   -0.658      0.145    -4.53  0.00000589\n2 RunnyNoseYes   0.0502     0.172     0.292 0.770     \n\n\n#2\n\n#show results \nglance(model_fit_3)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n1          945.     729  -472.  949.  958.     945.         728   730\n\n\nPlot model as box whisker plot\n\ntidy(model_fit_3) %>% \n  dwplot(dot_args = list(size = 1, color = \"black\"),vline = geom_vline(xintercept = 0, colour = \"black\", linetype = 2),\n         whisker_args = list(color = \"blue\")) + xlab(\"Estimate\") + theme_minimal()\n\n\n\n\nRegression estimate for runny nose as a predictor is nearly 0.05\nplot performance\n\nmp3 = check_model(model_fit_3$fit)\n#model_1_performance\n\nAdjust the check_model output figure titles. This allows all the text on the axis to be legible.\n\n#mp1\np3 = plot(mp3)\n\n\n\np3[[1]] = p3[[1]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np3[[2]] = p3[[2]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np3[[3]] = p3[[3]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np3[[4]] = p3[[4]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np3"
  },
  {
    "objectID": "fluanalysis/code/fitting.html#fits-another-logistic-model-to-the-categorical-outcome-using-all-important-predictors-of-interest.",
    "href": "fluanalysis/code/fitting.html#fits-another-logistic-model-to-the-categorical-outcome-using-all-important-predictors-of-interest.",
    "title": "Flu Anlaysis - Model Fitting",
    "section": "Fits another logistic model to the categorical outcome using all (important) predictors of interest.",
    "text": "Fits another logistic model to the categorical outcome using all (important) predictors of interest.\n\n#specify linear model logistic_reg() which generalized linear model for binary outcomes\nmodel4 = logistic_reg() %>% \n  set_engine(\"glm\") #fit model generalized linear model \n\n#fit the linear model to our main predictor\nmodel_fit_4 = model4 %>% \n  fit(Nausea ~., data=data)\n  model_fit_4\n\nparsnip model object\n\n\nCall:  stats::glm(formula = Nausea ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n           (Intercept)    SwollenLymphNodesYes      ChestCongestionYes  \n              0.222870               -0.251083                0.275554  \n       ChillsSweatsYes      NasalCongestionYes              CoughYNYes  \n              0.274097                0.425817               -0.140423  \n             SneezeYes              FatigueYes      SubjectiveFeverYes  \n              0.176724                0.229062                0.277741  \n           HeadacheYes            WeaknessMild        WeaknessModerate  \n              0.331259               -0.121606                0.310849  \n        WeaknessSevere           WeaknessYNYes      CoughIntensityMild  \n              0.823187                      NA               -0.220794  \nCoughIntensityModerate    CoughIntensitySevere             CoughYN2Yes  \n             -0.362678               -0.950544                      NA  \n           MyalgiaMild         MyalgiaModerate           MyalgiaSevere  \n             -0.004146                0.204743                0.120758  \n          MyalgiaYNYes            RunnyNoseYes               AbPainYes  \n                    NA                0.045324                0.939304  \n          ChestPainYes             DiarrheaYes                EyePnYes  \n              0.070777                1.063934               -0.341991  \n           InsomniaYes             ItchyEyeYes                EarPnYes  \n              0.084175               -0.063364               -0.181719  \n            HearingYes          PharyngitisYes           BreathlessYes  \n              0.323052                0.275364                0.526801  \n            ToothPnYes               VisionYes                VomitYes  \n              0.480649                0.125498                2.458466  \n             WheezeYes                BodyTemp  \n             -0.304435               -0.031246  \n\nDegrees of Freedom: 729 Total (i.e. Null);  695 Residual\nNull Deviance:      944.7 \nResidual Deviance: 751.5    AIC: 821.5\n\n\nTable of model summary\n\ntidy(model_fit_4) #table of model summary\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)             0.223     7.83     0.0285  0.977 \n 2 SwollenLymphNodesYes   -0.251     0.196   -1.28    0.200 \n 3 ChestCongestionYes      0.276     0.213    1.30    0.195 \n 4 ChillsSweatsYes         0.274     0.288    0.952   0.341 \n 5 NasalCongestionYes      0.426     0.255    1.67    0.0944\n 6 CoughYNYes             -0.140     0.519   -0.271   0.787 \n 7 SneezeYes               0.177     0.210    0.840   0.401 \n 8 FatigueYes              0.229     0.372    0.616   0.538 \n 9 SubjectiveFeverYes      0.278     0.225    1.23    0.218 \n10 HeadacheYes             0.331     0.285    1.16    0.245 \n# … with 28 more rows\n\n\nPlot model as box whisker plot\n\ntidy(model_fit_4) %>% \n  dwplot(dot_args = list(size = 1, color = \"black\"),vline = geom_vline(xintercept = 0, colour = \"black\", linetype = 2),\n         whisker_args = list(color = \"blue\")) + xlab(\"Estimate\") + theme_minimal()\n\n\n\n\n**Vomiting has the highest estimate at 2.4\nPlot performance\n\nmp4 = check_model(model_fit_4$fit)\n\nAdjust the check_model output figure titles. This allows all the text on the axis to be legible.\n\np4 = plot(mp4)\n\n\n\np4[[1]] = p4[[1]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np4[[2]] = p4[[2]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np4[[3]] = p4[[3]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np4[[4]] = p4[[4]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np4[[5]] = p4[[5]] + theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))\np4"
  },
  {
    "objectID": "fluanalysis/code/fitting.html#compares-the-model-results-for-the-categorical-model-with-just-the-main-predictor-and-all-predictors.",
    "href": "fluanalysis/code/fitting.html#compares-the-model-results-for-the-categorical-model-with-just-the-main-predictor-and-all-predictors.",
    "title": "Flu Anlaysis - Model Fitting",
    "section": "Compares the model results for the categorical model with just the main predictor and all predictors.",
    "text": "Compares the model results for the categorical model with just the main predictor and all predictors.\n\ncompare_performance(model_fit_3,model_fit_4)\n\n# Comparison of Model Performance Indices\n\nName        | Model | AIC (weights) | AICc (weights) | BIC (weights) | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n-------------------------------------------------------------------------------------------------------------------------------------------------\nmodel_fit_3 |  _glm | 948.6 (<.001) |  948.6 (<.001) | 957.8 (>.999) | 1.169e-04 | 0.477 | 1.139 |    0.647 |  -107.871 |           0.012 | 0.545\nmodel_fit_4 |  _glm | 821.5 (>.999) |  825.1 (>.999) | 982.2 (<.001) |     0.247 | 0.414 | 1.040 |    0.515 |      -Inf |           0.002 | 0.658"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html",
    "href": "fluanalysis/code/modeleval.html",
    "title": "Flu Anlaysis - Model Eval",
    "section": "",
    "text": "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.1     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nhere() starts at /Users/deannalanier/Desktop/All_Classes_UGA/2023Spr_Classes/MADA/deannalanier-MADA-portfolio\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.3\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.4     ✔ yardstick    1.1.0\n✔ recipes      1.0.5     \n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nLoading required package: Matrix\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-7"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#load-the-data",
    "href": "fluanalysis/code/modeleval.html#load-the-data",
    "title": "Flu Anlaysis - Model Eval",
    "section": "Load the data",
    "text": "Load the data\n\n#path to clean data\ndata = readRDS(here(\"fluanalysis\", \"data\", \"cleandata.rds\")) #load RDS file"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#check-the-data",
    "href": "fluanalysis/code/modeleval.html#check-the-data",
    "title": "Flu Anlaysis - Model Eval",
    "section": "Check the data",
    "text": "Check the data\n\n#check the data to make sure it has loaded properly\nhead(data)\n\n  SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion CoughYN Sneeze\n1               Yes              No           No              No     Yes     No\n2               Yes             Yes           No             Yes     Yes     No\n3               Yes             Yes          Yes             Yes      No    Yes\n4               Yes             Yes          Yes             Yes     Yes    Yes\n5               Yes              No          Yes              No      No     No\n6                No              No          Yes              No     Yes    Yes\n  Fatigue SubjectiveFever Headache Weakness WeaknessYN CoughIntensity CoughYN2\n1     Yes             Yes      Yes     Mild        Yes         Severe      Yes\n2     Yes             Yes      Yes   Severe        Yes         Severe      Yes\n3     Yes             Yes      Yes   Severe        Yes           Mild      Yes\n4     Yes             Yes      Yes   Severe        Yes       Moderate      Yes\n5     Yes             Yes      Yes Moderate        Yes           None       No\n6     Yes             Yes      Yes Moderate        Yes       Moderate      Yes\n   Myalgia MyalgiaYN RunnyNose AbPain ChestPain Diarrhea EyePn Insomnia\n1     Mild       Yes        No     No        No       No    No       No\n2   Severe       Yes        No     No        No       No    No       No\n3   Severe       Yes       Yes    Yes       Yes       No    No      Yes\n4   Severe       Yes       Yes     No        No       No    No      Yes\n5     Mild       Yes        No     No        No       No   Yes      Yes\n6 Moderate       Yes        No     No       Yes      Yes    No       No\n  ItchyEye Nausea EarPn Hearing Pharyngitis Breathless ToothPn Vision Vomit\n1       No     No    No      No         Yes         No      No     No    No\n2       No     No   Yes     Yes         Yes         No      No     No    No\n3       No    Yes    No      No         Yes        Yes     Yes     No    No\n4       No    Yes   Yes      No         Yes         No      No     No    No\n5       No    Yes    No      No         Yes         No      No     No    No\n6       No    Yes    No      No         Yes        Yes      No     No    No\n  Wheeze BodyTemp\n1     No     98.3\n2     No    100.4\n3     No    100.8\n4    Yes     98.8\n5     No    100.5\n6    Yes     98.4"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#data-splitting",
    "href": "fluanalysis/code/modeleval.html#data-splitting",
    "title": "Flu Anlaysis - Model Eval",
    "section": "Data Splitting",
    "text": "Data Splitting\n\n# set seed \nset.seed(456)\n\n## Split the data into test and training\ndata_split=initial_split(data,strata = Nausea)\n\n#create training and test\ndata_train=training(data_split)\ndata_test=testing(data_split)"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#create-workflow-fit-model",
    "href": "fluanalysis/code/modeleval.html#create-workflow-fit-model",
    "title": "Flu Anlaysis - Model Eval",
    "section": "Create Workflow Fit Model",
    "text": "Create Workflow Fit Model\n\n#logistical model because of categorical outcome\nrecipe_1=recipe(Nausea~.,data=data_train)\nlog_mod=logistic_reg()%>%\n  set_engine(\"glm\")\n\n\n#create workflow\nworkflow_1=workflow()%>%\n  add_model(log_mod)%>%\n  add_recipe(recipe_1)\nworkflow_1\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n#fit the model with training set\nmodel_fit=workflow_1%>%\n  fit(data=data_train)\nmodel_fit%>%\n  extract_fit_parsnip()%>%\n  tidy()\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)           -3.21       9.15     -0.351  0.726 \n 2 SwollenLymphNodesYes  -0.435      0.231    -1.88   0.0596\n 3 ChestCongestionYes     0.0827     0.250     0.330  0.741 \n 4 ChillsSweatsYes        0.119      0.332     0.358  0.720 \n 5 NasalCongestionYes     0.327      0.295     1.11   0.267 \n 6 CoughYNYes            -0.501      0.590    -0.849  0.396 \n 7 SneezeYes              0.214      0.251     0.854  0.393 \n 8 FatigueYes             0.391      0.463     0.845  0.398 \n 9 SubjectiveFeverYes     0.423      0.260     1.62   0.104 \n10 HeadacheYes            0.415      0.342     1.22   0.224 \n# … with 28 more rows\n\n\n\n#model evaluation\npredict(model_fit,data_train)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 547 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 No         \n 6 No         \n 7 No         \n 8 No         \n 9 No         \n10 No         \n# … with 537 more rows\n\nmodel_train_eval=augment(model_fit,data_train)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n\n\n#ROC curve to estimate area\nmodel_train_eval %>% \n  roc_curve(truth = Nausea, .pred_No) %>%\n  autoplot()\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\nℹ The deprecated feature was likely used in the yardstick package.\n  Please report the issue at <\u001b]8;;https://github.com/tidymodels/yardstick/issues\u0007https://github.com/tidymodels/yardstick/issues\u001b]8;;\u0007>.\n\n\n\n\n#AUC\nmodel_train_eval %>%\n  roc_auc(truth = Nausea, .pred_No)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.790"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#predict",
    "href": "fluanalysis/code/modeleval.html#predict",
    "title": "Flu Anlaysis - Model Eval",
    "section": "Predict",
    "text": "Predict\n\n# eval\npredict(model_fit,data_test)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 Yes        \n 6 Yes        \n 7 No         \n 8 Yes        \n 9 Yes        \n10 No         \n# … with 173 more rows\n\nmodel_test_eval=augment(model_fit,data_test)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n#ROC curve to estimate area\nmodel_test_eval%>%\n  roc_curve(truth=Nausea,.pred_No)%>%\n  autoplot()\n\n\n\n#AUC\nmodel_test_eval=augment(model_fit,data_test)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nmodel_test_eval%>%\n  roc_auc(truth=Nausea,.pred_No)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.707"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#fit-model-with-main-predictor",
    "href": "fluanalysis/code/modeleval.html#fit-model-with-main-predictor",
    "title": "Flu Anlaysis - Model Eval",
    "section": "fit model with main predictor",
    "text": "fit model with main predictor\n\nset.seed(5678)\n\nrecipe_2=recipe(Nausea~RunnyNose,data=data_train)\n\n#logistical model\nlog_mod=logistic_reg()%>%\n  set_engine(\"glm\")\n\nworkflow_2=workflow()%>%\n  add_model(log_mod)%>%\n  add_recipe(recipe_2)\nworkflow_2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\nmodel_2=workflow_2%>%\n  fit(data=data_train)\nmodel_2%>%\n  extract_fit_parsnip()%>%\n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  -0.625       0.170   -3.67   0.000242\n2 RunnyNoseYes  0.00301     0.200    0.0150 0.988"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#use-model-to-predict",
    "href": "fluanalysis/code/modeleval.html#use-model-to-predict",
    "title": "Flu Anlaysis - Model Eval",
    "section": "Use model to predict",
    "text": "Use model to predict\n\n# model eval training set ROC\npredict(model_2,data_train)\n\n# A tibble: 547 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 No         \n 6 No         \n 7 No         \n 8 No         \n 9 No         \n10 No         \n# … with 537 more rows\n\nmodel_train_eval_2=augment(model_2,data_train)\nmodel_train_eval_2%>%\n  roc_curve(truth=Nausea,.pred_No)%>%\n  autoplot()\n\n\n\n#AUC\nmodel_train_eval_2%>%\n  roc_auc(truth=Nausea,.pred_No)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.500\n\n\n\n# ROC and prediction\npredict(model_2,data_test)\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 No         \n 6 No         \n 7 No         \n 8 No         \n 9 No         \n10 No         \n# … with 173 more rows\n\nmodel_test_eval_2=augment(model_2,data_test)\nmodel_test_eval_2%>%\n  roc_curve(truth=Nausea,.pred_No)%>%\n  autoplot()\n\n\n\n# AUC\nmodel_test_eval_2%>%\n  roc_auc(truth=Nausea,.pred_No)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.520\n\n\n\nThis section is added by Aidan Troha\nWe will be using the data from the cleaned flu analysis data, so we will need to load the data from the data folder.\n\ndat <- readRDS(here::here(\"fluanalysis\",\"data\",\"cleandata.rds\"))"
  },
  {
    "objectID": "dataanalysis-exercise/output/readme.html",
    "href": "dataanalysis-exercise/output/readme.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains results produced by the code, such as figures and tables.\nDepending on the size and type of your project, you can either place it all in a single folder or create sub-folders. For instance you could create a folder for figures, another for tables. Or you could create a sub-folder for dataset 1, another for dataset 2. Or you could have a subfolder for exploratory analysis, another for final analysis. The options are endless, choose whatever makes sense for your project. For this template, there is just a a single folder, but having sub-folders is often a good idea."
  },
  {
    "objectID": "dataanalysis-exercise/data/readme.html",
    "href": "dataanalysis-exercise/data/readme.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all data at various stages.\nThis data is being loaded/manipulated/changed/saved with code from the code folders.\nYou should place the raw data in the raw_data folder and not edit it. Ever!\nIdeally, load the raw data into R and do all changes there with code, so everything is automatically reproducible and documented.\nSometimes, you need to edit the files in the format you got. For instance, Excel files are sometimes so poorly formatted that it’s close to impossible to read them into R, or the persons you got the data from used color to code some information, which of course won’t import into R. In those cases, you might have to make modifications in a software other than R. If you need to make edits in whatever format you got the data (e.g. Excel), make a copy and place those copies in a separate folder, AND ONLY EDIT THOSE COPIES. Also, write down somewhere the edits you made.\nAdd as many sub-folders as suitable. If you only have a single processing step, one sub-folder for processed data is enough. If you have multiple stages of cleaning and processing, additional sub-folders might be useful. Adjust based on the complexity of your project.\nI suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data:\nhttp://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html",
    "href": "fluanalysis/code/machinelearning.html",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "",
    "text": "Focused on single outcome, the continuous, numerical value of Body Temperature."
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#load-libraries",
    "href": "fluanalysis/code/machinelearning.html#load-libraries",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "Load Libraries",
    "text": "Load Libraries\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.1     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nhere() starts at /Users/deannalanier/Desktop/All_Classes_UGA/2023Spr_Classes/MADA/deannalanier-MADA-portfolio\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\n\nLoading required package: rpart\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.3\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.4     ✔ yardstick    1.1.0\n✔ recipes      1.0.5     \n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ dials::prune()    masks rpart::prune()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nLoading required package: Matrix\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-7"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#load-the-data",
    "href": "fluanalysis/code/machinelearning.html#load-the-data",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "Load the data",
    "text": "Load the data\n\n#path to clean data\ndata = readRDS(here(\"fluanalysis\", \"data\", \"cleandata2.rds\")) #load RDS file"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#check-the-data",
    "href": "fluanalysis/code/machinelearning.html#check-the-data",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "Check the data",
    "text": "Check the data\n\n#check the data to make sure it has loaded properly\nhead(data)\n\n  SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion Sneeze Fatigue\n1               Yes              No           No              No     No     Yes\n2               Yes             Yes           No             Yes     No     Yes\n3               Yes             Yes          Yes             Yes    Yes     Yes\n4               Yes             Yes          Yes             Yes    Yes     Yes\n5               Yes              No          Yes              No     No     Yes\n6                No              No          Yes              No    Yes     Yes\n  SubjectiveFever Headache Weakness CoughIntensity  Myalgia RunnyNose AbPain\n1             Yes      Yes     Mild         Severe     Mild        No     No\n2             Yes      Yes   Severe         Severe   Severe        No     No\n3             Yes      Yes   Severe           Mild   Severe       Yes    Yes\n4             Yes      Yes   Severe       Moderate   Severe       Yes     No\n5             Yes      Yes Moderate           None     Mild        No     No\n6             Yes      Yes Moderate       Moderate Moderate        No     No\n  ChestPain Diarrhea EyePn Insomnia ItchyEye Nausea EarPn Pharyngitis\n1        No       No    No       No       No     No    No         Yes\n2        No       No    No       No       No     No   Yes         Yes\n3       Yes       No    No      Yes       No    Yes    No         Yes\n4        No       No    No      Yes       No    Yes   Yes         Yes\n5        No       No   Yes      Yes       No    Yes    No         Yes\n6       Yes      Yes    No       No       No    Yes    No         Yes\n  Breathless ToothPn Vomit Wheeze BodyTemp\n1         No      No    No     No     98.3\n2         No      No    No     No    100.4\n3        Yes     Yes    No     No    100.8\n4         No      No    No    Yes     98.8\n5         No      No    No     No    100.5\n6        Yes      No    No    Yes     98.4\n\n\n#Setup\n\nSet random seed to 123\nSplit the dataset into 70% training 30% testing. Use BodyTemp as stratification\nDo 5-fold cross-validation, 5 times repeated.\nCreate a recipe for the data and fitting"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#set-random-seed-to-123",
    "href": "fluanalysis/code/machinelearning.html#set-random-seed-to-123",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "1. Set random seed to 123",
    "text": "1. Set random seed to 123\n\n# set seed \nset.seed(123)"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#split-the-data",
    "href": "fluanalysis/code/machinelearning.html#split-the-data",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "2. Split the data",
    "text": "2. Split the data\n\n## Split the data into test and training\ndata_split = initial_split(data,strata = BodyTemp, prop = 7/10)\n\n#create training and test\ndata_train=training(data_split)\ndata_test=testing(data_split)"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#cross-validation",
    "href": "fluanalysis/code/machinelearning.html#cross-validation",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "3. Cross validation",
    "text": "3. Cross validation\n\n# 5 fold cross-validation 5 times repeated 5x5\n# stratify on Body Temp\n# use vfold_cv to create a resample object for the training data \n\n#CV on training data\nfold_train = vfold_cv(data_train, v = 5, repeats = 5, strata = BodyTemp)\nfold_train\n\n#  5-fold cross-validation repeated 5 times using stratification \n# A tibble: 25 × 3\n   splits            id      id2  \n   <list>            <chr>   <chr>\n 1 <split [405/103]> Repeat1 Fold1\n 2 <split [405/103]> Repeat1 Fold2\n 3 <split [406/102]> Repeat1 Fold3\n 4 <split [408/100]> Repeat1 Fold4\n 5 <split [408/100]> Repeat1 Fold5\n 6 <split [405/103]> Repeat2 Fold1\n 7 <split [405/103]> Repeat2 Fold2\n 8 <split [406/102]> Repeat2 Fold3\n 9 <split [408/100]> Repeat2 Fold4\n10 <split [408/100]> Repeat2 Fold5\n# … with 15 more rows\n\n#CV on test data\nfold_test = vfold_cv(data_test, v = 5, repeats = 5, strata = BodyTemp)\nfold_test\n\n#  5-fold cross-validation repeated 5 times using stratification \n# A tibble: 25 × 3\n   splits           id      id2  \n   <list>           <chr>   <chr>\n 1 <split [175/47]> Repeat1 Fold1\n 2 <split [176/46]> Repeat1 Fold2\n 3 <split [179/43]> Repeat1 Fold3\n 4 <split [179/43]> Repeat1 Fold4\n 5 <split [179/43]> Repeat1 Fold5\n 6 <split [175/47]> Repeat2 Fold1\n 7 <split [176/46]> Repeat2 Fold2\n 8 <split [179/43]> Repeat2 Fold3\n 9 <split [179/43]> Repeat2 Fold4\n10 <split [179/43]> Repeat2 Fold5\n# … with 15 more rows"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#create-a-recipe-for-the-data-and-fitting",
    "href": "fluanalysis/code/machinelearning.html#create-a-recipe-for-the-data-and-fitting",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "4. Create a recipe for the data and fitting",
    "text": "4. Create a recipe for the data and fitting\n\n# categorical variables as dummy variables \n#pick all nominal predictor variables \n\ndata_recipe = recipe(BodyTemp ~ ., data = data_train) %>%\n  step_dummy(all_nominal(), -all_outcomes())"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#tree",
    "href": "fluanalysis/code/machinelearning.html#tree",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "Tree",
    "text": "Tree\n\nModel specification\n\ntree_spec = decision_tree(cost_complexity = tune(),tree_depth = tune())%>%\n  set_engine(\"rpart\")%>%\n  set_mode(\"regression\")\n\ntree_spec\n\nDecision Tree Model Specification (regression)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nWorkflow definition\n\n#create workflow\ntree_workflow = workflow()%>%\n  add_model(tree_spec)%>%\n  add_recipe(data_recipe) #recipe created in step 4 of the setup\n\n\n\ntuning grid specification\n\ntree_grid = grid_regular(cost_complexity(),\n                         tree_depth(),\n                         levels = 5)\ntree_grid\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             <dbl>      <int>\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# … with 15 more rows\n\n#depth\ntree_grid %>%\n  count(tree_depth)\n\n# A tibble: 5 × 2\n  tree_depth     n\n       <int> <int>\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5\n\n\n\n\ntuning using cross validation\n\ntree_cv = tree_workflow %>%\n  tune_grid(\n    resamples = fold_train,\n    grid = tree_grid\n  )\n\n! Fold1, Repeat1: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold2, Repeat1: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold3, Repeat1: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold4, Repeat1: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold5, Repeat1: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold1, Repeat2: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold2, Repeat2: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold3, Repeat2: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold4, Repeat2: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold5, Repeat2: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold1, Repeat3: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold2, Repeat3: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold3, Repeat3: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold4, Repeat3: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold5, Repeat3: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold1, Repeat4: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold2, Repeat4: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold3, Repeat4: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold4, Repeat4: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold5, Repeat4: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold1, Repeat5: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold2, Repeat5: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold3, Repeat5: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold4, Repeat5: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n! Fold5, Repeat5: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n\n\n\ntree_cv\n\n# Tuning results\n# 5-fold cross-validation repeated 5 times using stratification \n# A tibble: 25 × 5\n   splits            id      id2   .metrics          .notes          \n   <list>            <chr>   <chr> <list>            <list>          \n 1 <split [405/103]> Repeat1 Fold1 <tibble [50 × 6]> <tibble [1 × 3]>\n 2 <split [405/103]> Repeat1 Fold2 <tibble [50 × 6]> <tibble [1 × 3]>\n 3 <split [406/102]> Repeat1 Fold3 <tibble [50 × 6]> <tibble [1 × 3]>\n 4 <split [408/100]> Repeat1 Fold4 <tibble [50 × 6]> <tibble [1 × 3]>\n 5 <split [408/100]> Repeat1 Fold5 <tibble [50 × 6]> <tibble [1 × 3]>\n 6 <split [405/103]> Repeat2 Fold1 <tibble [50 × 6]> <tibble [1 × 3]>\n 7 <split [405/103]> Repeat2 Fold2 <tibble [50 × 6]> <tibble [1 × 3]>\n 8 <split [406/102]> Repeat2 Fold3 <tibble [50 × 6]> <tibble [1 × 3]>\n 9 <split [408/100]> Repeat2 Fold4 <tibble [50 × 6]> <tibble [1 × 3]>\n10 <split [408/100]> Repeat2 Fold5 <tibble [50 × 6]> <tibble [1 × 3]>\n# … with 15 more rows\n\nThere were issues with some computations:\n\n  - Warning(s) x25: There was 1 warning in `dplyr::summarise()`. ℹ In argument: `.est...\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\n\n#use collect metrics to give tibble with the results from the tuning\ntree_cv %>%\n  collect_metrics()\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric .estimator     mean     n  std_err .config\n             <dbl>      <int> <chr>   <chr>         <dbl> <int>    <dbl> <chr>  \n 1    0.0000000001          1 rmse    standard     1.19      25  0.0181  Prepro…\n 2    0.0000000001          1 rsq     standard     0.0361    25  0.00422 Prepro…\n 3    0.0000000178          1 rmse    standard     1.19      25  0.0181  Prepro…\n 4    0.0000000178          1 rsq     standard     0.0361    25  0.00422 Prepro…\n 5    0.00000316            1 rmse    standard     1.19      25  0.0181  Prepro…\n 6    0.00000316            1 rsq     standard     0.0361    25  0.00422 Prepro…\n 7    0.000562              1 rmse    standard     1.19      25  0.0181  Prepro…\n 8    0.000562              1 rsq     standard     0.0361    25  0.00422 Prepro…\n 9    0.1                   1 rmse    standard     1.21      25  0.0177  Prepro…\n10    0.1                   1 rsq     standard   NaN          0 NA       Prepro…\n# … with 40 more rows\n\n\n\n\nModel Evaluation\nLook at diagnostics using autoplot().\n\ntree_cv %>% autoplot()\n\n\n\n\nGet the model that the tuning process has determined is the best using select_best() and finalize_workflow().\n\ntree_cv %>%\n  show_best(metric = \"rmse\")\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            <dbl>      <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>       \n1    0.0000000001          1 rmse    standard    1.19    25  0.0181 Preprocesso…\n2    0.0000000178          1 rmse    standard    1.19    25  0.0181 Preprocesso…\n3    0.00000316            1 rmse    standard    1.19    25  0.0181 Preprocesso…\n4    0.000562              1 rmse    standard    1.19    25  0.0181 Preprocesso…\n5    0.0000000001          4 rmse    standard    1.20    25  0.0182 Preprocesso…\n\n\n\ntree_best = tree_cv %>%\n  select_best(metric = \"rmse\")\ntree_best\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            <dbl>      <int> <chr>                \n1    0.0000000001          1 Preprocessor1_Model01\n\n\nFinalize workflow with the fit() function\n\ntree_f_workflow = tree_workflow %>%\n  finalize_workflow(tree_best)\n\ntree_f_fit = tree_f_workflow %>% fit(data=data_train)\ntree_f_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 508 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n1) root 508 742.9363 98.93642  \n  2) Sneeze_Yes>=0.5 280 259.6477 98.69107 *\n  3) Sneeze_Yes< 0.5 228 445.7356 99.23772 *\n\n\n\n#plot tree\nrpart.plot(extract_fit_parsnip(tree_f_fit)$fit)\n\nWarning: Cannot retrieve the data used to build the model (model.frame: object '..y' not found).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.\n\n\n\n\n\n\nevaluate the final fit\n\n#predicted and residuals\ntree_residuals = tree_f_fit %>%\n  augment(data_train) %>% #use augment() to make predictions from train data\n  select(c(.pred, BodyTemp)) %>%\n  mutate(.resid = BodyTemp - .pred) #calculate residuals and make new row.\n\ntree_residuals\n\n# A tibble: 508 × 3\n   .pred BodyTemp .resid\n   <dbl>    <dbl>  <dbl>\n 1  99.2     97.8 -1.44 \n 2  99.2     98.1 -1.14 \n 3  98.7     98.1 -0.591\n 4  98.7     98.2 -0.491\n 5  98.7     97.8 -0.891\n 6  98.7     98.2 -0.491\n 7  98.7     98.1 -0.591\n 8  99.2     98   -1.24 \n 9  99.2     97.7 -1.54 \n10  99.2     98.2 -1.04 \n# … with 498 more rows\n\n\n\n# Plot predicted values vs actual values\nplot_tree_predicted = tree_residuals %>%\n  ggplot(aes(x = BodyTemp, y = .pred)) + \n  geom_point() + \n  labs(title = \"Predicted outcomes vs Actual Outcomes\", \n       x = \"Body Temp Actual\", \n       y = \"Body Temp Prediction\")\nplot_tree_predicted\n\n\n\n\n\n# Plot predicted values vs residuals\nplot_tree_residual = ggplot(tree_residuals, \n                              aes(y = .resid, \n                              x = .pred)) + \n  geom_point() + \n  labs(title = \"Prediction Outcomes vs Residuals: Decision Tree\", \n       x = \"Body Temp Prediction\", \n       y = \"Residuals\")\nplot(plot_tree_residual) \n\n\n\n\n\n\n\nperformance\n\ntree_cv %>%\n  show_best(metric = \"rmse\", n=1)\n\n# A tibble: 1 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            <dbl>      <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>       \n1    0.0000000001          1 rmse    standard    1.19    25  0.0181 Preprocesso…"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#lasso",
    "href": "fluanalysis/code/machinelearning.html#lasso",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "LASSO",
    "text": "LASSO\n\nModel specification\n\n#mixture = 1 -> glmnet will remove irrelevant predictors\nlasso_mod = linear_reg(penalty = tune(), mixture = 1) %>% \n  set_engine(\"glmnet\")\n\n\n\nWorkflow definition\n\nlasso_workflow = workflow() %>%\n  add_model(lasso_mod) %>%\n  add_recipe(data_recipe)\n\n\n\ntuning grid specification\n\nlasso_grid = tibble(penalty = 10^seq(-4, -1, length.out = 30))\nlasso_grid %>% top_n(-6)\n\nSelecting by penalty\n\n\n# A tibble: 6 × 1\n   penalty\n     <dbl>\n1 0.0001  \n2 0.000127\n3 0.000161\n4 0.000204\n5 0.000259\n6 0.000329\n\nlasso_grid %>% top_n(6)\n\nSelecting by penalty\n\n\n# A tibble: 6 × 1\n  penalty\n    <dbl>\n1  0.0304\n2  0.0386\n3  0.0489\n4  0.0621\n5  0.0788\n6  0.1   \n\n\n\n\ntuning using cross validation\n\nlasso_cv = lasso_workflow %>%\n  tune_grid(resamples = fold_train,\n            grid = lasso_grid,\n            control = control_grid(verbose = FALSE, save_pred = TRUE),\n            metrics = metric_set(rmse))\n\nlasso_cv%>% collect_metrics()\n\n# A tibble: 30 × 7\n    penalty .metric .estimator  mean     n std_err .config              \n      <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1 0.0001   rmse    standard    1.18    25  0.0167 Preprocessor1_Model01\n 2 0.000127 rmse    standard    1.18    25  0.0167 Preprocessor1_Model02\n 3 0.000161 rmse    standard    1.18    25  0.0167 Preprocessor1_Model03\n 4 0.000204 rmse    standard    1.18    25  0.0167 Preprocessor1_Model04\n 5 0.000259 rmse    standard    1.18    25  0.0167 Preprocessor1_Model05\n 6 0.000329 rmse    standard    1.18    25  0.0167 Preprocessor1_Model06\n 7 0.000418 rmse    standard    1.18    25  0.0167 Preprocessor1_Model07\n 8 0.000530 rmse    standard    1.18    25  0.0167 Preprocessor1_Model08\n 9 0.000672 rmse    standard    1.18    25  0.0167 Preprocessor1_Model09\n10 0.000853 rmse    standard    1.18    25  0.0167 Preprocessor1_Model10\n# … with 20 more rows\n\n\n\n\nModel Evaluation\nLook at diagnostics using autoplot().\n\nlasso_cv %>% autoplot()\n\n\n\n\nGet the model that the tuning process has determined is the best using select_best() and finalize_workflow().\n\nlasso_cv %>%\n  show_best(metric = \"rmse\")\n\n# A tibble: 5 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1  0.0621 rmse    standard    1.15    25  0.0169 Preprocessor1_Model28\n2  0.0489 rmse    standard    1.15    25  0.0169 Preprocessor1_Model27\n3  0.0386 rmse    standard    1.15    25  0.0169 Preprocessor1_Model26\n4  0.0788 rmse    standard    1.16    25  0.0171 Preprocessor1_Model29\n5  0.0304 rmse    standard    1.16    25  0.0169 Preprocessor1_Model25\n\n\n\nlasso_best = lasso_cv %>%\n  select_best(metric = \"rmse\")\nlasso_best\n\n# A tibble: 1 × 2\n  penalty .config              \n    <dbl> <chr>                \n1  0.0621 Preprocessor1_Model28\n\n\nFinalize workflow with the fit() function\n\nlasso_f_workflow = lasso_workflow %>%\n  finalize_workflow(lasso_best)\n\nlasso_f_fit = lasso_f_workflow %>% fit(data=data_train)\nlasso_f_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev   Lambda\n1   0  0.00 0.271900\n2   2  1.24 0.247700\n3   2  2.67 0.225700\n4   2  3.86 0.205700\n5   2  4.85 0.187400\n6   2  5.67 0.170800\n7   2  6.35 0.155600\n8   2  6.91 0.141800\n9   5  7.57 0.129200\n10  5  8.27 0.117700\n11  8  9.06 0.107200\n12  8  9.81 0.097710\n13  9 10.44 0.089030\n14  9 11.09 0.081120\n15  9 11.63 0.073920\n16 10 12.12 0.067350\n17 10 12.56 0.061370\n18 12 13.00 0.055910\n19 14 13.45 0.050950\n20 16 13.85 0.046420\n21 19 14.24 0.042300\n22 19 14.59 0.038540\n23 19 14.87 0.035120\n24 22 15.17 0.032000\n25 22 15.44 0.029150\n26 22 15.67 0.026560\n27 22 15.85 0.024200\n28 23 16.01 0.022050\n29 24 16.15 0.020090\n30 25 16.28 0.018310\n31 25 16.39 0.016680\n32 25 16.49 0.015200\n33 25 16.56 0.013850\n34 26 16.63 0.012620\n35 27 16.69 0.011500\n36 27 16.73 0.010480\n37 27 16.77 0.009547\n38 27 16.81 0.008698\n39 28 16.84 0.007926\n40 29 16.86 0.007222\n41 29 16.88 0.006580\n42 29 16.90 0.005995\n43 29 16.91 0.005463\n44 29 16.92 0.004978\n45 30 16.93 0.004535\n46 30 16.94 0.004132\n\n...\nand 22 more lines.\n\n\n\n#plot for how the number of predictors included in the LASSO model changes with the tuning parameter\nx = lasso_f_fit$fit$fit$fit\nplot(x, \"lambda\")\n\n\n\n\n\nevaluate the final fit (repeat)\n\nlasso_residual = lasso_f_fit %>%\n  augment(data_train) %>% \n  select(c(.pred, BodyTemp)) %>%\n  mutate(resid = BodyTemp - .pred) \nlasso_residual\n\n# A tibble: 508 × 3\n   .pred BodyTemp  resid\n   <dbl>    <dbl>  <dbl>\n 1  98.8     97.8 -0.950\n 2  98.8     98.1 -0.719\n 3  98.5     98.1 -0.360\n 4  98.8     98.2 -0.606\n 5  98.7     97.8 -0.907\n 6  98.7     98.2 -0.523\n 7  98.4     98.1 -0.257\n 8  99.3     98   -1.26 \n 9  98.9     97.7 -1.24 \n10  99.0     98.2 -0.769\n# … with 498 more rows\n\n\n\n# Plot predicted values vs actual values\nplot_lasso_predicted = lasso_residual %>%\n  ggplot(aes(x = BodyTemp, y = .pred)) + \n  geom_point() + \n  labs(title = \"Predicted Outcomes vs Actual Outcomes\", \n       x = \"Body Temp Actual\", \n       y = \"Body Temp Prediction\")\nplot_lasso_predicted\n\n\n\n\n\n# Plot predicted values vs residuals\nplot_lasso_residual = lasso_residual %>% \n  ggplot(aes(x = resid, y = .pred)) + \n  geom_point() +\n  labs(title = \"Predictions vs Residual\", \n       x = \"Residuals\", \n       y = \"Body Temp Prediction\")\nplot_lasso_residual\n\n\n\n\n\n\n\nperformance\n\nlasso_cv %>%\n  show_best(metric = \"rmse\", n=1)\n\n# A tibble: 1 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1  0.0621 rmse    standard    1.15    25  0.0169 Preprocessor1_Model28"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#random-forest",
    "href": "fluanalysis/code/machinelearning.html#random-forest",
    "title": "Flu Anlaysis - Machine Learning",
    "section": "Random Forest",
    "text": "Random Forest\n\nModel specification\n\ncores = parallel::detectCores()\ncores\n\n[1] 10\n\nrandomfor_model <-\n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%\n  set_engine(\"ranger\", num.threads = cores) %>%\n  set_mode(\"regression\")\n\n\n\nWorkflow definition\n\nrandomfor_workflow <-\n  workflow() %>%\n  add_model(randomfor_model) %>%\n  add_recipe(data_recipe)\n\n\n\ntuning grid specification\n\nrandomfor_model\n\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nEngine-Specific Arguments:\n  num.threads = cores\n\nComputational engine: ranger \n\n\n\nextract_parameter_set_dials(randomfor_model)\n\nCollection of 2 parameters for tuning\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      min_n min_n nparam[+]\n\nModel parameters needing finalization:\n   # Randomly Selected Predictors ('mtry')\n\nSee `?dials::finalize` or `?dials::update.parameters` for more information.\n\n\n\n\ntuning using cross validation\n\nrandomfor_cv = randomfor_workflow %>%\n  tune_grid(resamples = fold_train,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(rmse))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n\nrandomfor_cv %>% \n  collect_metrics()\n\n# A tibble: 25 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1    13    13 rmse    standard    1.19    25  0.0166 Preprocessor1_Model01\n 2     5    36 rmse    standard    1.17    25  0.0165 Preprocessor1_Model02\n 3    16    28 rmse    standard    1.18    25  0.0166 Preprocessor1_Model03\n 4    30    40 rmse    standard    1.18    25  0.0168 Preprocessor1_Model04\n 5    11    30 rmse    standard    1.17    25  0.0164 Preprocessor1_Model05\n 6     7    26 rmse    standard    1.17    25  0.0166 Preprocessor1_Model06\n 7    22    26 rmse    standard    1.19    25  0.0165 Preprocessor1_Model07\n 8    10    11 rmse    standard    1.19    25  0.0166 Preprocessor1_Model08\n 9     7     2 rmse    standard    1.20    25  0.0161 Preprocessor1_Model09\n10     9     6 rmse    standard    1.19    25  0.0159 Preprocessor1_Model10\n# … with 15 more rows\n\n\n\n\nModel Evaluation\nLook at diagnostics using autoplot().\n\nautoplot(randomfor_cv)\n\n\n\n\nGet the model that the tuning process has determined is the best using select_best() and finalize_workflow().\n\nrandomfor_cv %>%\n  show_best(metric = \"rmse\")\n\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     6    33 rmse    standard    1.17    25  0.0166 Preprocessor1_Model23\n2     5    36 rmse    standard    1.17    25  0.0165 Preprocessor1_Model02\n3     7    26 rmse    standard    1.17    25  0.0166 Preprocessor1_Model06\n4     2    12 rmse    standard    1.17    25  0.0167 Preprocessor1_Model25\n5     2     4 rmse    standard    1.17    25  0.0166 Preprocessor1_Model19\n\n\n\nrandomfor_best = randomfor_cv %>%\n  select_best(metric = \"rmse\")\nrandomfor_best\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  <int> <int> <chr>                \n1     6    33 Preprocessor1_Model23\n\n\nfinalize workflow\n\nrandomfor_f_workflow = randomfor_workflow %>%\n  finalize_workflow(randomfor_best)\n\nrandomfor_f_fit = randomfor_f_workflow %>% fit(data=data_train)\nrandomfor_f_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~6L,      x), num.trees = ~1000, min.node.size = min_rows(~33L, x),      num.threads = ~cores, verbose = FALSE, seed = sample.int(10^5,          1)) \n\nType:                             Regression \nNumber of trees:                  1000 \nSample size:                      508 \nNumber of independent variables:  31 \nMtry:                             6 \nTarget node size:                 33 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       1.373913 \nR squared (OOB):                  0.06240402 \n\n\n\nevaluate the final fit (repeat)\n\n# get predicted and residual values in one dataset \nrandomfor_residual = randomfor_f_fit %>%\n  augment(data_train) %>% \n  select(c(.pred, BodyTemp)) %>%\n  mutate(resid = BodyTemp - .pred) \nrandomfor_residual\n\n# A tibble: 508 × 3\n   .pred BodyTemp  resid\n   <dbl>    <dbl>  <dbl>\n 1  98.7     97.8 -0.901\n 2  98.5     98.1 -0.448\n 3  98.7     98.1 -0.554\n 4  98.7     98.2 -0.523\n 5  98.8     97.8 -0.990\n 6  98.5     98.2 -0.306\n 7  98.3     98.1 -0.206\n 8  99.1     98   -1.12 \n 9  98.8     97.7 -1.09 \n10  98.9     98.2 -0.667\n# … with 498 more rows\n\n\n\n# Plot actual values vs predicted values\nplot_randomfor_predicted = randomfor_residual %>%\n  ggplot(aes(x = BodyTemp, y = .pred)) + \n  geom_point() + \n  labs(title = \"Predictions vs Actual\", \n       x = \"Body Temp Actual\", \n       y = \"Body Temp Prediction\")\nplot_randomfor_predicted\n\n\n\n\n\n# Plot predicted values vs residuals\nplot_randomfor_residual = randomfor_residual %>% \n  ggplot(aes(x = resid, y = .pred)) + \n  geom_point() +\n  labs(title = \"Predictions vs Residual\", \n       x = \"Residual\", \n       y = \"Body Temp Prediction\")\nplot_randomfor_residual\n\n\n\n\n\n\n\nperformance\n\nrandomfor_cv %>%\n  show_best(metric = \"rmse\", n=1)\n\n# A tibble: 1 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     6    33 rmse    standard    1.17    25  0.0166 Preprocessor1_Model23"
  },
  {
    "objectID": "tidytuesday_exercise2.html",
    "href": "tidytuesday_exercise2.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "library(tidytuesdayR)\nlibrary(tidyverse) \n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(lubridate) #change data type to data\n\nLoading required package: timechange\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(skimr) #skim dataframes\nlibrary(gt) #create tables \nlibrary(knitr) #format table output\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(here)\n\nhere() starts at /Users/deannalanier/Desktop/All_Classes_UGA/2023Spr_Classes/MADA/deannalanier-MADA-portfolio\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.3\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.4     ✔ yardstick    1.1.0\n✔ recipes      1.0.5     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard()        masks purrr::discard()\n✖ dplyr::filter()          masks stats::filter()\n✖ recipes::fixed()         masks stringr::fixed()\n✖ kableExtra::group_rows() masks dplyr::group_rows()\n✖ dplyr::lag()             masks stats::lag()\n✖ yardstick::spec()        masks readr::spec()\n✖ recipes::step()          masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(rpart)\n\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\nlibrary(glmnet)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-7\n\nlibrary(rpart.plot)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\n\n\n\n\n\ndata = tidytuesdayR::tt_load('2023-04-11')\n\n--- Compiling #TidyTuesday Information for 2023-04-11 ----\n\n\n--- There are 2 files available ---\n\n\n--- Starting Download ---\n\n\n\n    Downloading file 1 of 2: `egg-production.csv`\n    Downloading file 2 of 2: `cage-free-percentages.csv`\n\n\n--- Download complete ---\n\nsummary(data)\n\n                      Length Class       Mode\negg-production        6      spec_tbl_df list\ncage-free-percentages 4      spec_tbl_df list\n\n\n\n#format into dataframes\neggData = data[[\"egg-production\"]][, 1:5] #save without the source as it is not important\ncagefreeData = data[[\"cage-free-percentages\"]][, 1:3] #save without the source as it is not important\n\n\nskim(eggData)\n\n\n\n\nData summary\n\n\n\n\nName\n\n\neggData\n\n\n\n\nNumber of rows\n\n\n220\n\n\n\n\nNumber of columns\n\n\n5\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\ncharacter\n\n\n2\n\n\n\n\nDate\n\n\n1\n\n\n\n\nnumeric\n\n\n2\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\n\nVariable type: character\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmin\n\n\nmax\n\n\nempty\n\n\nn_unique\n\n\nwhitespace\n\n\n\n\n\n\nprod_type\n\n\n0\n\n\n1\n\n\n10\n\n\n13\n\n\n0\n\n\n2\n\n\n0\n\n\n\n\nprod_process\n\n\n0\n\n\n1\n\n\n3\n\n\n23\n\n\n0\n\n\n3\n\n\n0\n\n\n\n\n\nVariable type: Date\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmin\n\n\nmax\n\n\nmedian\n\n\nn_unique\n\n\n\n\n\n\nobserved_month\n\n\n0\n\n\n1\n\n\n2016-07-31\n\n\n2021-02-28\n\n\n2018-11-15\n\n\n56\n\n\n\n\n\nVariable type: numeric\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmean\n\n\nsd\n\n\np0\n\n\np25\n\n\np50\n\n\np75\n\n\np100\n\n\nhist\n\n\n\n\n\n\nn_hens\n\n\n0\n\n\n1\n\n\n110839873\n\n\n124121204\n\n\n13500000\n\n\n17284500\n\n\n59939500\n\n\n125539250\n\n\n341166000\n\n\n▇▁▁▁▂\n\n\n\n\nn_eggs\n\n\n0\n\n\n1\n\n\n2606667580\n\n\n3082457619\n\n\n298074240\n\n\n423962023\n\n\n1154550000\n\n\n2963010996\n\n\n8601000000\n\n\n▇▁▁▁▂\n\n\n\n\n\n\n\n\nstr(cagefreeData)\n\ntibble [96 × 3] (S3: tbl_df/tbl/data.frame)\n $ observed_month: Date[1:96], format: \"2007-12-31\" \"2008-12-31\" ...\n $ percent_hens  : num [1:96] 3.2 3.5 3.6 4.4 5.4 6 5.9 5.7 8.6 9.9 ...\n $ percent_eggs  : num [1:96] NA NA NA NA NA NA NA NA NA NA ...\n\n\n###Explore Egg Data\n\n#table of the egg data\ntibble(eggData)\n\n# A tibble: 220 × 5\n   observed_month prod_type     prod_process   n_hens     n_eggs\n   <date>         <chr>         <chr>           <dbl>      <dbl>\n 1 2016-07-31     hatching eggs all          57975000 1147000000\n 2 2016-08-31     hatching eggs all          57595000 1142700000\n 3 2016-09-30     hatching eggs all          57161000 1093300000\n 4 2016-10-31     hatching eggs all          56857000 1126700000\n 5 2016-11-30     hatching eggs all          57116000 1096600000\n 6 2016-12-31     hatching eggs all          57750000 1132900000\n 7 2017-01-31     hatching eggs all          57991000 1123400000\n 8 2017-02-28     hatching eggs all          58286000 1014500000\n 9 2017-03-31     hatching eggs all          58735000 1128500000\n10 2017-04-30     hatching eggs all          59072000 1097200000\n# … with 210 more rows\n\n\nEgg Production Data Dictionary\n\n\n\n\n\n\n\n\nVariable\nClass\nDescription\n\n\n\n\nobserved_month\ndouble\nMonth in which report observations are collected,Dates are recorded in ISO 8601 format YYYY-MM-DD\n\n\nprod_type\ncharacter\ntype of egg product: hatching, table eggs\n\n\nprod_process\ncharacter\ntype of production process and housing: cage-free (organic), cage-free (non-organic), all. The value ‘all’ includes cage-free and conventional housing.\n\n\nn_hens\ndouble\nnumber of hens produced by hens for a given month-type-process combo\n\n\nn_eggs\ndouble\nnumber of eggs producing eggs for a given month-type-process combo\n\n\n\nPlot the data to explore\n\n#Plot the data \n  # Relationship between the number of eggs laid and the number of hens \nggplot() +\n    geom_point(data = eggData, aes(x = n_eggs, y = n_hens, color = prod_process), shape = 20) +\n    theme_bw()+ggtitle(\"Number of Hens vs. Number of Eggs Laid\") +\n    labs(x = \"Eggs\", y = \"Hens\")+\n  facet_wrap(.~prod_type)\n\n\n\n\nPlot the number of eggs hatched by year\n\n#Separate by the product type \nggplot()+\n  geom_point(aes(x=observed_month, y= n_eggs, group=prod_process, color=prod_process), data=eggData,shape = 20)+\n  theme_bw()+ggtitle(\"Number of Eggs Laid per Year\") +\n  labs(x = \"Eggs\", y = \"Year\")+\n  facet_wrap(.~prod_type)\n\n\n\n\nPlot the number of eggs hatched by year\n\n#No separation  \nggplot()+\n  geom_point(aes(x=observed_month, y= n_eggs, group=prod_process, color=prod_process), data=eggData,shape = 20)+\n  theme_bw()+ggtitle(\"Number of Eggs Laid per Year\") +\n  labs(x = \"Eggs\", y = \"Year\")\n\n\n\n\n\n\n\n\nThis will determine the outcome of interest and, if applicable, main predictor(s) of interest.\n\nggplot() +\n    geom_point(data = eggData, aes(x = n_hens, y = n_eggs, color = prod_process), shape = 19) +\n    ggtitle(\"Laying Efficency\", subtitle = \"Number of hens vs number of eggs laid\") +\n    labs(x = \"Hens\", y = \"Eggs\") +\n    xlim(0, 70000000) +\n    ylim(0, 1700000000)\n\nWarning: Removed 55 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nggplot() +\n    geom_line(data = eggData, aes(x = observed_month, y = n_eggs, color = prod_process)) +\n    ggtitle(\"Eggs Production over time\", subtitle = \"\") +\n    labs(x = \"Time\", y = \"Eggs\")\n\n\n\n\n\n\n\n\n\n\nFit at least 4 different ML models to the data using the tidymodels framework we practiced. Use the CV approach for model training/fitting. Explore the quality of each model by looking at performance, residuals, uncertainty, etc. All of this should still be evaluated using the training/CV data. You can of course recycle code from the previous exercise, but I also encourage you to explore further, e.g. try different ML models or use different metrics. You might have to do that anyway, depending on your question/outcome.\n\n\n\nBased on the model evaluations, decide on one model you think is overall best. Explain why. It doesn’t have to be the model with the best performance. You make the choice, just explain why you picked the one you picked.\n\n\n\nAs a final, somewhat honest assessment of the quality of the model you chose, evaluate it (performance, residuals, uncertainty, etc.) on the test data. This is the only time you are allowed to touch the test data, and only once. Report model performance on the test data.\n\n\n\nSummarize everything you did and found in a discussion. Of course, your Rmd file should contain commentary/documentation on everything you do for each step."
  }
]